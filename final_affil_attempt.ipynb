{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262e91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "final_logic_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles...\n",
      "Loaded 3336 titles.\n",
      "Parsing latex affiliation sections... this may take a moment.\n",
      "Successfully parsed 10685 papers.\n",
      "Total number of papers in output file with download errors: 12917\n",
      "Loading country list...\n",
      "Loaded 253 countries.\n",
      "Matching and filtering papers...\n",
      "\n",
      "Task complete! Saved to 'extracted_affiliations.csv'.\n",
      "Found matches for 1041 papers.\n",
      "Of the 3336 papers in your request, 2152 had LaTeX download errors recorded.\n",
      "Number of papers with NO country matches (excluding errors): 149\n",
      "\n",
      "Papers with no country matches:\n",
      "- Probabilistic mapping between multiparticle production variables and the depth of maximum in proton-induced extensive air showers\n",
      "- The Leinster-Cobbold diversity index as a criterion for sub-clustering\n",
      "- The Youngest Star Clusters in the Large Magellanic Cloud\n",
      "- On the presence of a fifth force at the Galactic Center\n",
      "- Heating, Excitation, Dissociation, and Ionization of Molecules by High-Energy Photons in Planetary Atmospheres\n",
      "- Conceptual framework for the application of deep neural networks to surface composition reconstruction from Mercury's exospheric data\n",
      "- REBELS-MOSFIRE: Weak CIII] Emission is Typical Among Extremely UV-bright, Massive Galaxies at $z\\sim7$\n",
      "- Fully analytical propagator for lunar satellite orbits in closed form\n",
      "- A chemically etched D-band waveguide orthomode transducer for CMB measurements\n",
      "- Precursor Activity Preceding Interacting Supernovae I: Bridging the Gap with SN 2022mop\n",
      "- Baryon Acoustic Oscillations in tomographic Angular Density and Redshift Fluctuations\n",
      "- The PAU Survey: Measuring intrinsic galaxy alignments in deep wide fields as a function of colour, luminosity, stellar mass and redshift\n",
      "- A Hubble Constant Determination Through Quasar Time Delays and Type Ia Supernovae\n",
      "- A Bayesian PINN Framework for Barrow-Tsallis Holographic Dark Energy with Neutrinos: Toward a Resolution of the Hubble Tension\n",
      "- Forward vs Backward: Improving BAO Constraints with Field-Level Inference\n",
      "- Clumps as multiscale structures in cosmic noon galaxies\n",
      "- HST pre-imaging of a free-floating planet candidate microlensing event\n",
      "- GDL 1.1, a smart and green language\n",
      "- Encyclopedia Magneticum: Scaling Relations from Cosmic Dawn to Present Day\n",
      "- Accurate and efficient likelihood modeling for large-scale CMB data\n",
      "... and 129 more.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can a multi-tracer approach improve the constr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First large scale spatial and velocity pattern...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Stellar Magnesium to Silicon ratio in the at...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photometric and spectroscopic variability of b...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homogeneous measurements of proximity zone siz...</td>\n",
       "      <td>[$^{1}$Leiden Observatory, Leiden University, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Can a multi-tracer approach improve the constr...   \n",
       "1  First large scale spatial and velocity pattern...   \n",
       "2  A Stellar Magnesium to Silicon ratio in the at...   \n",
       "3  Photometric and spectroscopic variability of b...   \n",
       "4  Homogeneous measurements of proximity zone siz...   \n",
       "\n",
       "                                               lines  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4  [$^{1}$Leiden Observatory, Leiden University, ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load the titles to search for\n",
    "print(\"Loading titles...\")\n",
    "with open('papers_with_missing_affiliations.txt', 'r') as f:\n",
    "    titles = [line.strip() for line in f if line.strip()]\n",
    "data = pd.DataFrame(titles, columns=['title'])\n",
    "print(f\"Loaded {len(data)} titles.\")\n",
    "\n",
    "# 2. Parse the latex affiliations file\n",
    "print(\"Parsing latex affiliation sections... this may take a moment.\")\n",
    "paper_sections = {}\n",
    "current_paper = None\n",
    "affiliation_started = False\n",
    "failed_download_count = 0\n",
    "papers_with_errors = []\n",
    "\n",
    "with open(\"latex_affiliations_output.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"PAPER: \"):\n",
    "            current_paper = line.replace(\"PAPER: \", \"\").strip()\n",
    "            paper_sections[current_paper] = []\n",
    "            affiliation_started = False\n",
    "        elif line.startswith(\"ERROR: Failed to download LaTeX sources\"):\n",
    "            if current_paper:\n",
    "                papers_with_errors.append(current_paper)\n",
    "                failed_download_count += 1\n",
    "        elif line.startswith(\"AFFILIATION SECTION:\"):\n",
    "            affiliation_started = True\n",
    "        elif line.startswith(\"-\" * 10):\n",
    "            continue\n",
    "        elif current_paper and affiliation_started:\n",
    "            stripped = line.strip()\n",
    "            if stripped:\n",
    "                paper_sections[current_paper].append(line.rstrip('\\n'))\n",
    "\n",
    "print(f\"Successfully parsed {len(paper_sections)} papers.\")\n",
    "print(f\"Total number of papers in output file with download errors: {failed_download_count}\")\n",
    "\n",
    "# 3. Load the list of countries\n",
    "print(\"Loading country list...\")\n",
    "list_countries = pd.read_csv('world_coords.csv')['country'].tolist()\n",
    "list_countries.extend(['United States', 'United Kingdom', 'Canada', 'Australia', 'New Zealand', 'USA', 'UK', 'The Netherlands', 'China', 'South Korea',\n",
    "                       'UAE','The United Arab Emirates', 'The United States', 'The United Kingdom', 'The United States of America', 'Italy', 'France', 'Germany', 'Spain', 'Japan'])\n",
    "# Remove duplicates\n",
    "list_countries = list(set(list_countries))\n",
    "print(f\"Loaded {len(list_countries)} countries.\")\n",
    "\n",
    "# 4. Search and extract lines\n",
    "print(\"Matching and filtering papers...\")\n",
    "results = []\n",
    "no_match_papers = []\n",
    "error_titles_norm = set(t.strip().lower() for t in papers_with_errors)\n",
    "normalized_sections = {k.strip().lower(): k for k in paper_sections.keys()}\n",
    "\n",
    "for title in data['title']:\n",
    "    matching_lines = []\n",
    "    title_norm = str(title).strip().lower()\n",
    "    \n",
    "    is_error = title_norm in error_titles_norm\n",
    "    found_in_latex = title_norm in normalized_sections\n",
    "    \n",
    "    if found_in_latex:\n",
    "        original_key = normalized_sections[title_norm]\n",
    "        section_lines = paper_sections[original_key]\n",
    "        \n",
    "        for l in section_lines:\n",
    "            for country in list_countries:\n",
    "                if country in l:\n",
    "                    matching_lines.append(l.strip())\n",
    "    \n",
    "    # Track papers with no matches that aren't download errors\n",
    "    if not is_error and len(matching_lines) == 0:\n",
    "        no_match_papers.append(title)\n",
    "        \n",
    "    results.append({\n",
    "        'title': title,\n",
    "        'lines': matching_lines\n",
    "    })\n",
    "\n",
    "# 5. Save results\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv('extracted_affiliations.csv', index=False)\n",
    "print(f\"\\nTask complete! Saved to 'extracted_affiliations.csv'.\")\n",
    "print(f\"Found matches for {len(output_df[output_df['lines'].map(len) > 0])} papers.\")\n",
    "\n",
    "# Report on papers in 'data' that failed to download\n",
    "data_error_count = sum(1 for t in data['title'] if str(t).strip().lower() in error_titles_norm)\n",
    "print(f\"Of the {len(data)} papers in your request, {data_error_count} had LaTeX download errors recorded.\")\n",
    "\n",
    "# Report on papers with no matches\n",
    "print(f\"Number of papers with NO country matches (excluding errors): {len(no_match_papers)}\")\n",
    "if no_match_papers:\n",
    "    print(\"\\nPapers with no country matches:\")\n",
    "    for p in no_match_papers[:20]: # Show first 20\n",
    "        print(f\"- {p}\")\n",
    "    if len(no_match_papers) > 20:\n",
    "        print(f\"... and {len(no_match_papers)-20} more.\")\n",
    "\n",
    "output_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95ea08e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles...\n",
      "Loaded 3336 titles.\n",
      "Parsing latex affiliation sections... this may take a moment.\n",
      "Successfully parsed 5974 papers.\n",
      "Total number of papers in output file with download errors: 212\n",
      "Loading country list...\n",
      "Loaded 253 countries.\n",
      "Matching and filtering papers...\n",
      "\n",
      "Task complete! Saved to 'extracted_affiliations.csv'.\n",
      "Found matches for 1519 papers.\n",
      "Of the 3336 papers in your request, 126 had LaTeX download errors recorded.\n",
      "Number of papers with NO country matches (excluding errors): 1691\n",
      "\n",
      "Papers with no country matches:\n",
      "- Can a multi-tracer approach improve the constraints on the turnover scale?\n",
      "- Homogeneous measurements of proximity zone sizes for 59 quasars in the Epoch of Reionization\n",
      "- The COSMOS-Web Lens Survey (COWLS) III: forecasts versus data\n",
      "- JWST observations of segregated $^{12}$CO$_2$ and $^{13}$CO$_2$ ices in protostellar envelopes\n",
      "- A direct black hole mass measurement in a Little Red Dot at the Epoch of Reionization\n",
      "- Why the northern hemisphere needs a 30-40 m telescope and the science at stake: Massive stars in spiral galaxies\n",
      "- CAPERS-LRD-z9: A Gas Enshrouded Little Red Dot Hosting a Broad-line AGN at z=9.288\n",
      "- Stray and Scattered Light Considerations in a Non-contiguous Array of Commercial CMOS Sensors in a Space Mission\n",
      "- Probabilistic mapping between multiparticle production variables and the depth of maximum in proton-induced extensive air showers\n",
      "- MeerKAT view of Hickson Compact Groups: II. HI deficiency in the core and surrounding regions\n",
      "- Determining the Milky Way gravitational potential without selection functions\n",
      "- Computational Insights into the Chemical Reaction Networks of C3H6O3,C3H7O3 and C2H5O2: Implications for the Interstellar Medium\n",
      "- New constraints on the evolution of the MHI-M* scaling relation combining CHILES and MIGHTEE-HI data\n",
      "- Photometric Redshift Estimation for Rubin Observatory Data Preview 1 with Redshift Assessment Infrastructure Layers (RAIL)\n",
      "- X-ray polarization of reflected thermal emission\n",
      "- Inclusion of sulfur chemistry in a validated C/H/O/N chemical network: identification of key C/S coupling pathways\n",
      "- The Leinster-Cobbold diversity index as a criterion for sub-clustering\n",
      "- FRB 20250316A: A Brilliant and Nearby One-Off Fast Radio Burst Localized to 13 parsec Precision\n",
      "- The S-PLUS 12-band photometry as a powerful tool for discovery and classification: ten cataclysmic variables in a proof-of-concept study\n",
      "- All-sky search for short gravitational-wave bursts in the first part of the fourth LIGO-Virgo-KAGRA observing run\n",
      "... and 1671 more.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can a multi-tracer approach improve the constr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First large scale spatial and velocity pattern...</td>\n",
       "      <td>[Universit\\'e C\\^ote d'Azur, Observatoire de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Stellar Magnesium to Silicon ratio in the at...</td>\n",
       "      <td>[\\affil[1]{School of Earth and Space Explorati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photometric and spectroscopic variability of b...</td>\n",
       "      <td>[\\institute{Tartu Observatory, University of T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homogeneous measurements of proximity zone siz...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Can a multi-tracer approach improve the constr...   \n",
       "1  First large scale spatial and velocity pattern...   \n",
       "2  A Stellar Magnesium to Silicon ratio in the at...   \n",
       "3  Photometric and spectroscopic variability of b...   \n",
       "4  Homogeneous measurements of proximity zone siz...   \n",
       "\n",
       "                                               lines  \n",
       "0                                                 []  \n",
       "1  [Universit\\'e C\\^ote d'Azur, Observatoire de l...  \n",
       "2  [\\affil[1]{School of Earth and Space Explorati...  \n",
       "3  [\\institute{Tartu Observatory, University of T...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load the titles to search for\n",
    "print(\"Loading titles...\")\n",
    "with open('papers_with_missing_affiliations.txt', 'r') as f:\n",
    "    titles = [line.strip() for line in f if line.strip()]\n",
    "data = pd.DataFrame(titles, columns=['title'])\n",
    "print(f\"Loaded {len(data)} titles.\")\n",
    "\n",
    "# 2. Parse the latex affiliations file\n",
    "print(\"Parsing latex affiliation sections... this may take a moment.\")\n",
    "paper_sections = {}\n",
    "current_paper = None\n",
    "affiliation_started = False\n",
    "failed_download_count = 0\n",
    "papers_with_errors = []\n",
    "\n",
    "with open(\"latex_affiliations_output_2.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"PAPER: \"):\n",
    "            current_paper = line.replace(\"PAPER: \", \"\").strip()\n",
    "            paper_sections[current_paper] = []\n",
    "            affiliation_started = False\n",
    "        elif line.startswith(\"ERROR: Failed to download LaTeX sources\"):\n",
    "            if current_paper:\n",
    "                papers_with_errors.append(current_paper)\n",
    "                failed_download_count += 1\n",
    "        elif line.startswith(\"AFFILIATION SECTION:\"):\n",
    "            affiliation_started = True\n",
    "        elif line.startswith(\"-\" * 10):\n",
    "            continue\n",
    "        elif current_paper and affiliation_started:\n",
    "            stripped = line.strip()\n",
    "            if stripped:\n",
    "                paper_sections[current_paper].append(line.rstrip('\\n'))\n",
    "\n",
    "print(f\"Successfully parsed {len(paper_sections)} papers.\")\n",
    "print(f\"Total number of papers in output file with download errors: {failed_download_count}\")\n",
    "\n",
    "# 3. Load the list of countries\n",
    "print(\"Loading country list...\")\n",
    "list_countries = pd.read_csv('world_coords.csv')['country'].tolist()\n",
    "list_countries.extend(['United States', 'United Kingdom', 'Canada', 'Australia', 'New Zealand', 'USA', 'UK', 'The Netherlands', 'China', 'South Korea',\n",
    "                       'UAE','The United Arab Emirates', 'The United States', 'The United Kingdom', 'The United States of America', 'Italy', 'France', 'Germany', 'Spain', 'Japan'])\n",
    "# Remove duplicates\n",
    "list_countries = list(set(list_countries))\n",
    "print(f\"Loaded {len(list_countries)} countries.\")\n",
    "\n",
    "# 4. Search and extract lines\n",
    "print(\"Matching and filtering papers...\")\n",
    "results = []\n",
    "no_match_papers = []\n",
    "error_titles_norm = set(t.strip().lower() for t in papers_with_errors)\n",
    "normalized_sections = {k.strip().lower(): k for k in paper_sections.keys()}\n",
    "\n",
    "for title in data['title']:\n",
    "    matching_lines = []\n",
    "    title_norm = str(title).strip().lower()\n",
    "    \n",
    "    is_error = title_norm in error_titles_norm\n",
    "    found_in_latex = title_norm in normalized_sections\n",
    "    \n",
    "    if found_in_latex:\n",
    "        original_key = normalized_sections[title_norm]\n",
    "        section_lines = paper_sections[original_key]\n",
    "        \n",
    "        for l in section_lines:\n",
    "            for country in list_countries:\n",
    "                if country in l:\n",
    "                    matching_lines.append(l.strip())\n",
    "    \n",
    "    # Track papers with no matches that aren't download errors\n",
    "    if not is_error and len(matching_lines) == 0:\n",
    "        no_match_papers.append(title)\n",
    "        \n",
    "    results.append({\n",
    "        'title': title,\n",
    "        'lines': matching_lines\n",
    "    })\n",
    "\n",
    "# 5. Save results\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv('extracted_affiliations_2.csv', index=False)\n",
    "print(f\"\\nTask complete! Saved to 'extracted_affiliations.csv'.\")\n",
    "print(f\"Found matches for {len(output_df[output_df['lines'].map(len) > 0])} papers.\")\n",
    "\n",
    "# Report on papers in 'data' that failed to download\n",
    "data_error_count = sum(1 for t in data['title'] if str(t).strip().lower() in error_titles_norm)\n",
    "print(f\"Of the {len(data)} papers in your request, {data_error_count} had LaTeX download errors recorded.\")\n",
    "\n",
    "# Report on papers with no matches\n",
    "print(f\"Number of papers with NO country matches (excluding errors): {len(no_match_papers)}\")\n",
    "if no_match_papers:\n",
    "    print(\"\\nPapers with no country matches:\")\n",
    "    for p in no_match_papers[:20]: # Show first 20\n",
    "        print(f\"- {p}\")\n",
    "    if len(no_match_papers) > 20:\n",
    "        print(f\"... and {len(no_match_papers)-20} more.\")\n",
    "\n",
    "output_df.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
