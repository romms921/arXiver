{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "262e91f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7beab865",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('FINAL_ARXIV_2025_with_affiliations.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "final_logic_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles...\n",
      "Loaded 3336 titles.\n",
      "Parsing latex_affiliations_output.txt... this may take a moment.\n",
      "Successfully parsed 10685 papers.\n",
      "Total number of papers with download errors: 12917\n",
      "Saved titles with LaTeX errors to 'latex_error_papers.txt'\n",
      "Loading country list...\n",
      "Loaded 253 countries.\n",
      "Matching and filtering papers...\n",
      "\n",
      "Task complete! Saved to 'extracted_affiliations.csv'.\n",
      "Found matches for 1041 papers.\n",
      "Of the 3336 papers in your request, 2152 had LaTeX download errors recorded.\n",
      "Number of papers with NO country matches (excluding errors): 149\n",
      "\n",
      "Papers with no country matches:\n",
      "- Probabilistic mapping between multiparticle production variables and the depth of maximum in proton-induced extensive air showers\n",
      "- The Leinster-Cobbold diversity index as a criterion for sub-clustering\n",
      "- The Youngest Star Clusters in the Large Magellanic Cloud\n",
      "- On the presence of a fifth force at the Galactic Center\n",
      "- Heating, Excitation, Dissociation, and Ionization of Molecules by High-Energy Photons in Planetary Atmospheres\n",
      "- Conceptual framework for the application of deep neural networks to surface composition reconstruction from Mercury's exospheric data\n",
      "- REBELS-MOSFIRE: Weak CIII] Emission is Typical Among Extremely UV-bright, Massive Galaxies at $z\\sim7$\n",
      "- Fully analytical propagator for lunar satellite orbits in closed form\n",
      "- A chemically etched D-band waveguide orthomode transducer for CMB measurements\n",
      "- Precursor Activity Preceding Interacting Supernovae I: Bridging the Gap with SN 2022mop\n",
      "... and 139 more.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can a multi-tracer approach improve the constr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First large scale spatial and velocity pattern...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Stellar Magnesium to Silicon ratio in the at...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photometric and spectroscopic variability of b...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homogeneous measurements of proximity zone siz...</td>\n",
       "      <td>[$^{1}$Leiden Observatory, Leiden University, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Can a multi-tracer approach improve the constr...   \n",
       "1  First large scale spatial and velocity pattern...   \n",
       "2  A Stellar Magnesium to Silicon ratio in the at...   \n",
       "3  Photometric and spectroscopic variability of b...   \n",
       "4  Homogeneous measurements of proximity zone siz...   \n",
       "\n",
       "                                               lines  \n",
       "0                                                 []  \n",
       "1                                                 []  \n",
       "2                                                 []  \n",
       "3                                                 []  \n",
       "4  [$^{1}$Leiden Observatory, Leiden University, ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load the titles to search for\n",
    "print(\"Loading titles...\")\n",
    "with open('papers_with_missing_affiliations.txt', 'r') as f:\n",
    "    titles = [line.strip() for line in f if line.strip()]\n",
    "data = pd.DataFrame(titles, columns=['title'])\n",
    "print(f\"Loaded {len(data)} titles.\")\n",
    "\n",
    "# 2. Parse the latex affiliations file\n",
    "# Note: Using latex_affiliations_output.txt as primary source\n",
    "input_file = \"latex_affiliations_output.txt\"\n",
    "if not os.path.exists(input_file) and os.path.exists(\"latex_affiliations_output_2.txt\"):\n",
    "    input_file = \"latex_affiliations_output_2.txt\"\n",
    "\n",
    "print(f\"Parsing {input_file}... this may take a moment.\")\n",
    "paper_sections = {}\n",
    "current_paper = None\n",
    "affiliation_started = False\n",
    "failed_download_count = 0\n",
    "papers_with_errors = []\n",
    "\n",
    "with open(input_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"PAPER: \"):\n",
    "            current_paper = line.replace(\"PAPER: \", \"\").strip()\n",
    "            paper_sections[current_paper] = []\n",
    "            affiliation_started = False\n",
    "        elif line.startswith(\"ERROR: Failed to download LaTeX sources\"):\n",
    "            if current_paper:\n",
    "                papers_with_errors.append(current_paper)\n",
    "                failed_download_count += 1\n",
    "        elif line.startswith(\"AFFILIATION SECTION:\"):\n",
    "            affiliation_started = True\n",
    "        elif line.startswith(\"-\" * 10):\n",
    "            continue\n",
    "        elif current_paper and affiliation_started:\n",
    "            stripped = line.strip()\n",
    "            if stripped:\n",
    "                paper_sections[current_paper].append(line.rstrip('\\n'))\n",
    "\n",
    "print(f\"Successfully parsed {len(paper_sections)} papers.\")\n",
    "print(f\"Total number of papers with download errors: {failed_download_count}\")\n",
    "\n",
    "# Save errors to separate file\n",
    "with open('latex_error_papers.txt', 'w') as f:\n",
    "    for paper in papers_with_errors:\n",
    "        f.write(paper + \"\\n\")\n",
    "print(\"Saved titles with LaTeX errors to 'latex_error_papers.txt'\")\n",
    "\n",
    "# 3. Load the list of countries\n",
    "print(\"Loading country list...\")\n",
    "list_countries = pd.read_csv('world_coords.csv')['country'].tolist()\n",
    "list_countries.extend(['United States', 'United Kingdom', 'Canada', 'Australia', 'New Zealand', 'USA', 'UK', 'The Netherlands', 'China', 'South Korea',\n",
    "                       'UAE','The United Arab Emirates', 'The United States', 'The United Kingdom', 'The United States of America', 'Italy', 'France', 'Germany', 'Spain', 'Japan'])\n",
    "# Remove duplicates\n",
    "list_countries = list(set(list_countries))\n",
    "print(f\"Loaded {len(list_countries)} countries.\")\n",
    "\n",
    "# 4. Search and extract lines\n",
    "print(\"Matching and filtering papers...\")\n",
    "results = []\n",
    "no_match_papers = []\n",
    "error_titles_norm = set(t.strip().lower() for t in papers_with_errors)\n",
    "normalized_sections = {k.strip().lower(): k for k in paper_sections.keys()}\n",
    "\n",
    "for title in data['title']:\n",
    "    matching_lines = []\n",
    "    title_norm = str(title).strip().lower()\n",
    "    \n",
    "    is_error = title_norm in error_titles_norm\n",
    "    found_in_latex = title_norm in normalized_sections\n",
    "    \n",
    "    if found_in_latex:\n",
    "        original_key = normalized_sections[title_norm]\n",
    "        section_lines = paper_sections[original_key]\n",
    "        \n",
    "        for l in section_lines:\n",
    "            for country in list_countries:\n",
    "                if country in l:\n",
    "                    matching_lines.append(l.strip())\n",
    "    \n",
    "    # Track papers with no matches that aren't download errors\n",
    "    if not is_error and len(matching_lines) == 0:\n",
    "        no_match_papers.append(title)\n",
    "        \n",
    "    results.append({\n",
    "        'title': title,\n",
    "        'lines': matching_lines\n",
    "    })\n",
    "\n",
    "# 5. Save results\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv('extracted_affiliations.csv', index=False)\n",
    "print(f\"\\nTask complete! Saved to 'extracted_affiliations.csv'.\")\n",
    "print(f\"Found matches for {len(output_df[output_df['lines'].map(len) > 0])} papers.\")\n",
    "\n",
    "# Report on papers in 'data' that failed to download\n",
    "data_error_count = sum(1 for t in data['title'] if str(t).strip().lower() in error_titles_norm)\n",
    "print(f\"Of the {len(data)} papers in your request, {data_error_count} had LaTeX download errors recorded.\")\n",
    "\n",
    "# Report on papers with no matches\n",
    "print(f\"Number of papers with NO country matches (excluding errors): {len(no_match_papers)}\")\n",
    "if no_match_papers:\n",
    "    print(\"\\nPapers with no country matches:\")\n",
    "    for p in no_match_papers[:10]: # Show first 10\n",
    "        print(f\"- {p}\")\n",
    "    if len(no_match_papers) > 10:\n",
    "        print(f\"... and {len(no_match_papers)-10} more.\")\n",
    "\n",
    "output_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "95ea08e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading titles...\n",
      "Loaded 3336 titles.\n",
      "Parsing latex affiliation sections... this may take a moment.\n",
      "Successfully parsed 5974 papers.\n",
      "Total number of papers in output file with download errors: 212\n",
      "Loading country list...\n",
      "Loaded 253 countries.\n",
      "Matching and filtering papers...\n",
      "\n",
      "Task complete! Saved to 'extracted_affiliations.csv'.\n",
      "Found matches for 1519 papers.\n",
      "Of the 3336 papers in your request, 126 had LaTeX download errors recorded.\n",
      "Number of papers with NO country matches (excluding errors): 1691\n",
      "\n",
      "Papers with no country matches:\n",
      "- Can a multi-tracer approach improve the constraints on the turnover scale?\n",
      "- Homogeneous measurements of proximity zone sizes for 59 quasars in the Epoch of Reionization\n",
      "- The COSMOS-Web Lens Survey (COWLS) III: forecasts versus data\n",
      "- JWST observations of segregated $^{12}$CO$_2$ and $^{13}$CO$_2$ ices in protostellar envelopes\n",
      "- A direct black hole mass measurement in a Little Red Dot at the Epoch of Reionization\n",
      "- Why the northern hemisphere needs a 30-40 m telescope and the science at stake: Massive stars in spiral galaxies\n",
      "- CAPERS-LRD-z9: A Gas Enshrouded Little Red Dot Hosting a Broad-line AGN at z=9.288\n",
      "- Stray and Scattered Light Considerations in a Non-contiguous Array of Commercial CMOS Sensors in a Space Mission\n",
      "- Probabilistic mapping between multiparticle production variables and the depth of maximum in proton-induced extensive air showers\n",
      "- MeerKAT view of Hickson Compact Groups: II. HI deficiency in the core and surrounding regions\n",
      "- Determining the Milky Way gravitational potential without selection functions\n",
      "- Computational Insights into the Chemical Reaction Networks of C3H6O3,C3H7O3 and C2H5O2: Implications for the Interstellar Medium\n",
      "- New constraints on the evolution of the MHI-M* scaling relation combining CHILES and MIGHTEE-HI data\n",
      "- Photometric Redshift Estimation for Rubin Observatory Data Preview 1 with Redshift Assessment Infrastructure Layers (RAIL)\n",
      "- X-ray polarization of reflected thermal emission\n",
      "- Inclusion of sulfur chemistry in a validated C/H/O/N chemical network: identification of key C/S coupling pathways\n",
      "- The Leinster-Cobbold diversity index as a criterion for sub-clustering\n",
      "- FRB 20250316A: A Brilliant and Nearby One-Off Fast Radio Burst Localized to 13 parsec Precision\n",
      "- The S-PLUS 12-band photometry as a powerful tool for discovery and classification: ten cataclysmic variables in a proof-of-concept study\n",
      "- All-sky search for short gravitational-wave bursts in the first part of the fourth LIGO-Virgo-KAGRA observing run\n",
      "... and 1671 more.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can a multi-tracer approach improve the constr...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First large scale spatial and velocity pattern...</td>\n",
       "      <td>[Universit\\'e C\\^ote d'Azur, Observatoire de l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Stellar Magnesium to Silicon ratio in the at...</td>\n",
       "      <td>[\\affil[1]{School of Earth and Space Explorati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photometric and spectroscopic variability of b...</td>\n",
       "      <td>[\\institute{Tartu Observatory, University of T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homogeneous measurements of proximity zone siz...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Can a multi-tracer approach improve the constr...   \n",
       "1  First large scale spatial and velocity pattern...   \n",
       "2  A Stellar Magnesium to Silicon ratio in the at...   \n",
       "3  Photometric and spectroscopic variability of b...   \n",
       "4  Homogeneous measurements of proximity zone siz...   \n",
       "\n",
       "                                               lines  \n",
       "0                                                 []  \n",
       "1  [Universit\\'e C\\^ote d'Azur, Observatoire de l...  \n",
       "2  [\\affil[1]{School of Earth and Space Explorati...  \n",
       "3  [\\institute{Tartu Observatory, University of T...  \n",
       "4                                                 []  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Load the titles to search for\n",
    "print(\"Loading titles...\")\n",
    "with open('papers_with_missing_affiliations.txt', 'r') as f:\n",
    "    titles = [line.strip() for line in f if line.strip()]\n",
    "data = pd.DataFrame(titles, columns=['title'])\n",
    "print(f\"Loaded {len(data)} titles.\")\n",
    "\n",
    "# 2. Parse the latex affiliations file\n",
    "print(\"Parsing latex affiliation sections... this may take a moment.\")\n",
    "paper_sections = {}\n",
    "current_paper = None\n",
    "affiliation_started = False\n",
    "failed_download_count = 0\n",
    "papers_with_errors = []\n",
    "\n",
    "with open(\"latex_affiliations_output_2.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        if line.startswith(\"PAPER: \"):\n",
    "            current_paper = line.replace(\"PAPER: \", \"\").strip()\n",
    "            paper_sections[current_paper] = []\n",
    "            affiliation_started = False\n",
    "        elif line.startswith(\"ERROR: Failed to download LaTeX sources\"):\n",
    "            if current_paper:\n",
    "                papers_with_errors.append(current_paper)\n",
    "                failed_download_count += 1\n",
    "        elif line.startswith(\"AFFILIATION SECTION:\"):\n",
    "            affiliation_started = True\n",
    "        elif line.startswith(\"-\" * 10):\n",
    "            continue\n",
    "        elif current_paper and affiliation_started:\n",
    "            stripped = line.strip()\n",
    "            if stripped:\n",
    "                paper_sections[current_paper].append(line.rstrip('\\n'))\n",
    "\n",
    "print(f\"Successfully parsed {len(paper_sections)} papers.\")\n",
    "print(f\"Total number of papers in output file with download errors: {failed_download_count}\")\n",
    "\n",
    "# 3. Load the list of countries\n",
    "print(\"Loading country list...\")\n",
    "list_countries = pd.read_csv('world_coords.csv')['country'].tolist()\n",
    "list_countries.extend(['United States', 'United Kingdom', 'Canada', 'Australia', 'New Zealand', 'USA', 'UK', 'The Netherlands', 'China', 'South Korea',\n",
    "                       'UAE','The United Arab Emirates', 'The United States', 'The United Kingdom', 'The United States of America', 'Italy', 'France', 'Germany', 'Spain', 'Japan'])\n",
    "# Remove duplicates\n",
    "list_countries = list(set(list_countries))\n",
    "print(f\"Loaded {len(list_countries)} countries.\")\n",
    "\n",
    "# 4. Search and extract lines\n",
    "print(\"Matching and filtering papers...\")\n",
    "results = []\n",
    "no_match_papers = []\n",
    "error_titles_norm = set(t.strip().lower() for t in papers_with_errors)\n",
    "normalized_sections = {k.strip().lower(): k for k in paper_sections.keys()}\n",
    "\n",
    "for title in data['title']:\n",
    "    matching_lines = []\n",
    "    title_norm = str(title).strip().lower()\n",
    "    \n",
    "    is_error = title_norm in error_titles_norm\n",
    "    found_in_latex = title_norm in normalized_sections\n",
    "    \n",
    "    if found_in_latex:\n",
    "        original_key = normalized_sections[title_norm]\n",
    "        section_lines = paper_sections[original_key]\n",
    "        \n",
    "        for l in section_lines:\n",
    "            for country in list_countries:\n",
    "                if country in l:\n",
    "                    matching_lines.append(l.strip())\n",
    "    \n",
    "    # Track papers with no matches that aren't download errors\n",
    "    if not is_error and len(matching_lines) == 0:\n",
    "        no_match_papers.append(title)\n",
    "        \n",
    "    results.append({\n",
    "        'title': title,\n",
    "        'lines': matching_lines\n",
    "    })\n",
    "\n",
    "# 5. Save results\n",
    "output_df = pd.DataFrame(results)\n",
    "output_df.to_csv('extracted_affiliations_2.csv', index=False)\n",
    "print(f\"\\nTask complete! Saved to 'extracted_affiliations.csv'.\")\n",
    "print(f\"Found matches for {len(output_df[output_df['lines'].map(len) > 0])} papers.\")\n",
    "\n",
    "# Report on papers in 'data' that failed to download\n",
    "data_error_count = sum(1 for t in data['title'] if str(t).strip().lower() in error_titles_norm)\n",
    "print(f\"Of the {len(data)} papers in your request, {data_error_count} had LaTeX download errors recorded.\")\n",
    "\n",
    "# Report on papers with no matches\n",
    "print(f\"Number of papers with NO country matches (excluding errors): {len(no_match_papers)}\")\n",
    "if no_match_papers:\n",
    "    print(\"\\nPapers with no country matches:\")\n",
    "    for p in no_match_papers[:20]: # Show first 20\n",
    "        print(f\"- {p}\")\n",
    "    if len(no_match_papers) > 20:\n",
    "        print(f\"... and {len(no_match_papers)-20} more.\")\n",
    "\n",
    "output_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f12786ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "affils_1 = pd.read_csv('extracted_affiliations.csv')\n",
    "affils_2 = pd.read_csv('extracted_affiliations_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5d3a974e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[]'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "affils_1['lines'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8e21a213",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1041\n"
     ]
    }
   ],
   "source": [
    "counter_1 = 0\n",
    "for i in range(len(affils_1)):\n",
    "    line = affils_1['lines'][i]\n",
    "    if len(line) > 0 and line != '[]':\n",
    "        counter_1 += 1\n",
    "print(counter_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "57289e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1519\n"
     ]
    }
   ],
   "source": [
    "counter_2 = 0\n",
    "for i in range(len(affils_2)):\n",
    "    line = affils_2['lines'][i]\n",
    "    if len(line) > 0 and line != '[]':\n",
    "        counter_2 += 1\n",
    "print(counter_2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f347cd7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Promlematic papers:  776\n"
     ]
    }
   ],
   "source": [
    "total_counts = counter_1 + counter_2\n",
    "total_papers = 3336\n",
    "diff = total_papers - total_counts\n",
    "print(\"Promlematic papers: \", diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d83e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Number of Affiliations Found\n",
    "affil_counter_1 = 0\n",
    "for i in range(len(affils_1)):\n",
    "    if \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a969ce6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$^{1}$Leiden Observatory, Leiden University, P.O. Box 9513, 2300 RA Leiden, The Netherlands\\\\\\\\', '$^{1}$Leiden Observatory, Leiden University, P.O. Box 9513, 2300 RA Leiden, The Netherlands\\\\\\\\', '$^{2}$Department of Physics, Broida Hall, University of California, Santa Barbara, Santa Barbara, CA 93106-9530, USA\\\\\\\\', '$^{3}$MIT Kavli Institute for Astrophysics and Space Research, Massachusetts Institute of Technology, Cambridge, MA 02139, USA']\n",
      "Homogeneous measurements of proximity zone sizes for 59 quasars in the Epoch of Reionization\n"
     ]
    }
   ],
   "source": [
    "index = 4\n",
    "print(affils_1['lines'][index])\n",
    "print(affils_1['title'][index])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b9feb8",
   "metadata": {},
   "source": [
    "## Different Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576eecf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "method2_regex_cell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Method 2: Improved Regex-based extraction (Restored 'Final Fix')...\n",
      "Extraction complete! Saved to 'author_affiliations_method2.csv'.\n",
      "Stats: Processed 3336 papers.\n",
      "Papers with at least one author matched: 823\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>affiliations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can a multi-tracer approach improve the constr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First large scale spatial and velocity pattern...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Stellar Magnesium to Silicon ratio in the at...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photometric and spectroscopic variability of b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homogeneous measurements of proximity zone siz...</td>\n",
       "      <td>[Silvia Onorato$^{1}$\\thanks{E-mail: onorato@s...</td>\n",
       "      <td>[[]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Can a multi-tracer approach improve the constr...   \n",
       "1  First large scale spatial and velocity pattern...   \n",
       "2  A Stellar Magnesium to Silicon ratio in the at...   \n",
       "3  Photometric and spectroscopic variability of b...   \n",
       "4  Homogeneous measurements of proximity zone siz...   \n",
       "\n",
       "                                             authors affiliations  \n",
       "0                                                 []           []  \n",
       "1                                                 []           []  \n",
       "2                                                 []           []  \n",
       "3                                                 []           []  \n",
       "4  [Silvia Onorato$^{1}$\\thanks{E-mail: onorato@s...         [[]]  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Method 2: Robust Regex-based author and affiliation extraction\n",
    "print(\"Starting Method 2: Improved Regex-based extraction (Restored 'Final Fix')...\")\n",
    "\n",
    "# Regex to match \\author, \\affiliation, \\alsoaffiliation, and \\institute\n",
    "# Pattern: \\(author|affiliation|alsoaffiliation|institute)(?:\\[[^\\]]*\\])?\\s*\\{((?:[^{}]|\\{[^{}]*\\})+)\\}\n",
    "combined_pattern = re.compile(r'\\\\(author|affiliation|alsoaffiliation|institute)(?:\\[[^\\]]*\\])?\\s*\\{((?:[^{}]|\\{[^{}]*\\})+)\\}')\n",
    "\n",
    "results_method2 = []\n",
    "\n",
    "for title in data['title']:\n",
    "    author_list = []\n",
    "    affil_list_of_lists = [] # Each element is a list of affiliations for the corresponding author\n",
    "    \n",
    "    title_norm = str(title).strip().lower()\n",
    "    \n",
    "    if title_norm in normalized_sections:\n",
    "        original_key = normalized_sections[title_norm]\n",
    "        section_lines = paper_sections[original_key]\n",
    "        section_text = \" \".join(section_lines)\n",
    "        \n",
    "        matches = combined_pattern.finditer(section_text)\n",
    "        \n",
    "        current_author_index = -1\n",
    "        \n",
    "        for match in matches:\n",
    "            cmd_type = match.group(1)\n",
    "            content = match.group(2).strip()\n",
    "            \n",
    "            # Clean up content (remove multiple spaces, newlines)\n",
    "            content = re.sub(r'\\s+', ' ', content)\n",
    "            \n",
    "            if cmd_type == 'author':\n",
    "                author_list.append(content)\n",
    "                affil_list_of_lists.append([])\n",
    "                current_author_index += 1\n",
    "            elif cmd_type in ('affiliation', 'institute', 'alsoaffiliation'):\n",
    "                if current_author_index >= 0:\n",
    "                    affil_list_of_lists[current_author_index].append(content)\n",
    "        \n",
    "    results_method2.append({\n",
    "        'title': title,\n",
    "        'authors': author_list,\n",
    "        'affiliations': affil_list_of_lists\n",
    "    })\n",
    "\n",
    "# Create DataFrame and Save\n",
    "output_df_method2 = pd.DataFrame(results_method2)\n",
    "output_df_method2.to_csv('author_affiliations_method2.csv', index=False)\n",
    "\n",
    "print(f\"Extraction complete! Saved to 'author_affiliations_method2.csv'.\")\n",
    "print(f\"Stats: Processed {len(output_df_method2)} papers.\")\n",
    "print(f\"Papers with at least one author matched: {len(output_df_method2[output_df_method2['authors'].map(len) > 0])}\")\n",
    "\n",
    "output_df_method2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0eb4ad92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>authors</th>\n",
       "      <th>affiliations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can a multi-tracer approach improve the constr...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>First large scale spatial and velocity pattern...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A Stellar Magnesium to Silicon ratio in the at...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Photometric and spectroscopic variability of b...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homogeneous measurements of proximity zone siz...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3331</th>\n",
       "      <td>CubeSat Orbit Insertion Maneuvering Using J2 P...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332</th>\n",
       "      <td>New Bulgarian-Austrian project 'Joint observat...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3333</th>\n",
       "      <td>Year six photometric measurements of known Tra...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3334</th>\n",
       "      <td>Alfvén wave propagation, reflection and trappi...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3335</th>\n",
       "      <td>Large-Scale Structure Probes of the Post-Infla...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3336 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title authors affiliations\n",
       "0     Can a multi-tracer approach improve the constr...      []           []\n",
       "1     First large scale spatial and velocity pattern...      []           []\n",
       "2     A Stellar Magnesium to Silicon ratio in the at...      []           []\n",
       "3     Photometric and spectroscopic variability of b...      []           []\n",
       "4     Homogeneous measurements of proximity zone siz...      []           []\n",
       "...                                                 ...     ...          ...\n",
       "3331  CubeSat Orbit Insertion Maneuvering Using J2 P...      []           []\n",
       "3332  New Bulgarian-Austrian project 'Joint observat...      []           []\n",
       "3333  Year six photometric measurements of known Tra...      []           []\n",
       "3334  Alfvén wave propagation, reflection and trappi...      []           []\n",
       "3335  Large-Scale Structure Probes of the Post-Infla...      []           []\n",
       "\n",
       "[3336 rows x 3 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_df_method2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
