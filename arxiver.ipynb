{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T00:20:50.016421Z",
     "iopub.status.busy": "2025-12-28T00:20:50.016046Z",
     "iopub.status.idle": "2025-12-28T00:20:53.140063Z",
     "shell.execute_reply": "2025-12-28T00:20:53.139246Z",
     "shell.execute_reply.started": "2025-12-28T00:20:50.016393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install bitsandbytes -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T00:20:53.142270Z",
     "iopub.status.busy": "2025-12-28T00:20:53.142010Z",
     "iopub.status.idle": "2025-12-28T00:20:53.148043Z",
     "shell.execute_reply": "2025-12-28T00:20:53.147476Z",
     "shell.execute_reply.started": "2025-12-28T00:20:53.142241Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# %%writefile report_generation.py\n",
    "\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "def generate_missing_affiliation_report():\n",
    "    df = pd.read_csv(\"test_filled_21.csv\")\n",
    "    # Generate Report & Identify Done Papers\n",
    "    fully_filled_count = 0\n",
    "    partially_filled_count = 0\n",
    "    total_null_author_slots = 0\n",
    "    incomplete_indices = []\n",
    "    total_papers = len(df)\n",
    "\n",
    "    done_titles = []\n",
    "\n",
    "    for idx, row in df.iterrows():\n",
    "        try:\n",
    "            affs = ast.literal_eval(str(row['affiliations']))\n",
    "            null_count = sum(1 for a in affs if a is None)\n",
    "            total_null_author_slots += null_count\n",
    "            if null_count == 0: \n",
    "                fully_filled_count += 1\n",
    "                done_titles.append(row['title'])\n",
    "            else:\n",
    "                partially_filled_count += 1\n",
    "                incomplete_indices.append(idx)\n",
    "        except: \n",
    "            incomplete_indices.append(idx)\n",
    "\n",
    "    with open(\"missing_affiliations_reports.txt\", 'w', encoding='utf-8') as f:\n",
    "        f.write(\"=== MISSING AFFILIATIONS REPORT (V12) ===\\n\\n\")\n",
    "        f.write(f\"Total papers: {total_papers}\\n\")\n",
    "        f.write(f\"Fully filled papers: {fully_filled_count}\\n\")\n",
    "        f.write(f\"Partially filled papers: {partially_filled_count}\\n\")\n",
    "        f.write(f\"Total remaining null author affiliations: {total_null_author_slots}\\n\")\n",
    "        f.write(f\"\\nRemaining incomplete indices ({len(incomplete_indices)}):\\n\")\n",
    "        f.write(str(incomplete_indices) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_missing_affiliation_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T00:20:53.149129Z",
     "iopub.status.busy": "2025-12-28T00:20:53.148852Z",
     "iopub.status.idle": "2025-12-28T00:20:53.173309Z",
     "shell.execute_reply": "2025-12-28T00:20:53.172468Z",
     "shell.execute_reply.started": "2025-12-28T00:20:53.149100Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting model_and_extraction.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model_and_extraction.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "\n",
    "MODEL_ID = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "CSV_PATH = \"/kaggle/input/arxiver-data/test_filled_21.csv\"\n",
    "OUTPUT_CSV_PATH = \"test_filled_22.csv\"\n",
    "LATEX_FILES = [\"/kaggle/input/arxiver-data/latex_affiliations_output.txt\", \"/kaggle/input/arxiver-data/latex_affiliations_output_2.txt\"]\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "def load_model_for_batching():\n",
    "    print(f\"Loading {MODEL_ID} with padding support...\")\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_compute_dtype=torch.float16,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "    )\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_ID)\n",
    "    tokenizer.padding_side = \"left\"\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_ID,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\",\n",
    "        attn_implementation=\"sdpa\"\n",
    "    )\n",
    "    \n",
    "    return tokenizer, model\n",
    "\n",
    "\n",
    "def clean_latex_input(latex_code):\n",
    "    if not latex_code or len(latex_code) < 10:\n",
    "        return \"\"\n",
    "    cut_match = re.search(r'\\\\begin\\{abstract\\}|\\\\section\\{Intro', latex_code, re.IGNORECASE)\n",
    "    limit = cut_match.start() + 500 if cut_match else 4000\n",
    "    return latex_code[:limit]\n",
    "\n",
    "\n",
    "def batch_extract_affiliations(tokenizer, model, batch_data):\n",
    "    prompts = []\n",
    "\n",
    "    for item in batch_data:\n",
    "        short_latex = clean_latex_input(item['latex'])\n",
    "        if not short_latex:\n",
    "            prompts.append(\"NO DATA\")\n",
    "            continue\n",
    "\n",
    "        prompt_text = f\"\"\"Context:\n",
    "{short_latex}\n",
    "\n",
    "Task: Extract affiliations for: {item['authors']}.\n",
    "Rules:\n",
    "1. JSON format only. keys=authors, values=affiliations.\n",
    "2. Join multiple affiliations ONLY with a semicolon (;).\n",
    "3. If missing, use null.\n",
    "4. Output JSON only.\n",
    "\n",
    "JSON:\"\"\"\n",
    "\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Extract metadata to JSON. Use ';' separator.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt_text}\n",
    "        ]\n",
    "        prompts.append(tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True))\n",
    "\n",
    "    valid_indices = [i for i, p in enumerate(prompts) if p != \"NO DATA\"]\n",
    "    valid_prompts = [prompts[i] for i in valid_indices]\n",
    "\n",
    "    if not valid_prompts:\n",
    "        return [([None] * len(x['authors'])) for x in batch_data]\n",
    "\n",
    "    inputs = tokenizer(valid_prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=1600).to(model.device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        generated_ids = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=350,\n",
    "            temperature=0.1,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "\n",
    "    input_len = inputs.input_ids.shape[1]\n",
    "    responses = tokenizer.batch_decode(generated_ids[:, input_len:], skip_special_tokens=True)\n",
    "\n",
    "    results = []\n",
    "    response_ptr = 0\n",
    "\n",
    "    for i in range(len(batch_data)):\n",
    "        if i not in valid_indices:\n",
    "            results.append([None] * len(batch_data[i]['authors']))\n",
    "            continue\n",
    "\n",
    "        raw_text = responses[response_ptr]\n",
    "        response_ptr += 1\n",
    "\n",
    "        authors = batch_data[i]['authors']\n",
    "        aff_list = []\n",
    "\n",
    "        try:\n",
    "            clean_json = raw_text.replace(\"```json\", \"\").replace(\"```\", \"\").strip()\n",
    "            data = json.loads(clean_json)\n",
    "\n",
    "            for auth in authors:\n",
    "                val = data.get(auth, None)\n",
    "                if val:\n",
    "                    val = str(val)\n",
    "                    val = val.replace('\\n', '; ').replace('\\\\\\\\', '; ').replace(' and ', '; ')\n",
    "                    parts = [p.strip() for p in val.split(';') if p.strip()]\n",
    "                    seen = set()\n",
    "                    final_parts = [x for x in parts if not (x in seen or seen.add(x))]\n",
    "                    val = \"; \".join(final_parts)\n",
    "\n",
    "                aff_list.append(val)\n",
    "        except:\n",
    "            aff_list = [None] * len(authors)\n",
    "\n",
    "        results.append(aff_list)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T00:20:53.174700Z",
     "iopub.status.busy": "2025-12-28T00:20:53.174215Z",
     "iopub.status.idle": "2025-12-28T00:20:53.194291Z",
     "shell.execute_reply": "2025-12-28T00:20:53.193697Z",
     "shell.execute_reply.started": "2025-12-28T00:20:53.174677Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py\n",
    "\n",
    "import os\n",
    "import re\n",
    "import ast\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from accelerate import PartialState\n",
    "\n",
    "from model_and_extraction import (\n",
    "    load_model_for_batching,\n",
    "    batch_extract_affiliations,\n",
    "    CSV_PATH,\n",
    "    OUTPUT_CSV_PATH,\n",
    "    LATEX_FILES,\n",
    "    BATCH_SIZE,\n",
    ")\n",
    "\n",
    "distributed_state = PartialState()\n",
    "\n",
    "def main():\n",
    "    rank = distributed_state.process_index\n",
    "    tokenizer, model = load_model_for_batching()\n",
    "    df = pd.read_csv(CSV_PATH)\n",
    "    paper_latex_map = {}\n",
    "    for f_path in LATEX_FILES:\n",
    "        if os.path.exists(f_path):\n",
    "            with open(f_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "                sections = re.split(r'(?=PAPER:)', content)\n",
    "                for sec in sections:\n",
    "                    m = re.search(r'PAPER:\\s*(.+?)(?:\\n|$)', sec)\n",
    "                    if m:\n",
    "                        paper_latex_map[m.group(1).strip()] = sec\n",
    "    \n",
    "\n",
    "    def needs_processing(aff_str):\n",
    "        try:\n",
    "            affs = ast.literal_eval(str(aff_str))\n",
    "            return any(a is None for a in affs)\n",
    "        except:\n",
    "            return True\n",
    "\n",
    "    missing_indices = df[df['affiliations'].apply(needs_processing)].index.tolist()\n",
    "    batches = [\n",
    "        missing_indices[i:i + BATCH_SIZE]\n",
    "        for i in range(0, len(missing_indices), BATCH_SIZE)\n",
    "    ]\n",
    "    \n",
    "    local_results = []\n",
    "    import gc\n",
    "    gc.collect()\n",
    "    with distributed_state.split_between_processes(batches) as split_batches:\n",
    "        for idx_list in tqdm(split_batches, disable=not distributed_state.is_local_main_process):\n",
    "            batch_data = []\n",
    "\n",
    "            for idx in idx_list:\n",
    "                row = df.loc[idx]\n",
    "\n",
    "                try:\n",
    "                    authors = ast.literal_eval(str(row['authors']))\n",
    "                except:\n",
    "                    authors = []\n",
    "\n",
    "                latex = paper_latex_map.get(row['title'])\n",
    "                batch_data.append({\n",
    "                    \"idx\": idx,\n",
    "                    \"authors\": authors,\n",
    "                    \"latex\": latex\n",
    "                })\n",
    "\n",
    "            batch_results = batch_extract_affiliations(tokenizer, model, batch_data)\n",
    "\n",
    "            for i, item in enumerate(batch_data):\n",
    "                local_results.append((item[\"idx\"], str(batch_results[i])))\n",
    "\n",
    "    out_path = f\"partial_affiliations_gpu_{rank}.csv\"\n",
    "    pd.DataFrame(local_results, columns=[\"index\", \"affiliations\"]).to_csv(out_path, index=False)\n",
    "\n",
    "    distributed_state.print(f\"GPU {rank} finished.\")\n",
    "\n",
    "    if distributed_state.is_main_process:\n",
    "        files = glob.glob(\"partial_affiliations_gpu_*.csv\")\n",
    "        dfs = [pd.read_csv(f) for f in files]\n",
    "        merged = pd.concat(dfs).set_index(\"index\")\n",
    "\n",
    "        for idx, row in merged.iterrows():\n",
    "            df.at[idx, \"affiliations\"] = row[\"affiliations\"]\n",
    "\n",
    "        df.to_csv(OUTPUT_CSV_PATH, index=False)\n",
    "        print(f\"Final CSV saved → {OUTPUT_CSV_PATH}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-28T00:20:53.196081Z",
     "iopub.status.busy": "2025-12-28T00:20:53.195855Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W1228 00:21:00.677000 113 torch/distributed/run.py:774] \n",
      "W1228 00:21:00.677000 113 torch/distributed/run.py:774] *****************************************\n",
      "W1228 00:21:00.677000 113 torch/distributed/run.py:774] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. \n",
      "W1228 00:21:00.677000 113 torch/distributed/run.py:774] *****************************************\n",
      "Loading Qwen/Qwen2.5-7B-Instruct with padding support...\n",
      "Loading Qwen/Qwen2.5-7B-Instruct with padding support...\n",
      "tokenizer_config.json: 7.30kB [00:00, 32.2MB/s]\n",
      "vocab.json: 2.78MB [00:00, 45.8MB/s]\n",
      "merges.txt: 1.67MB [00:00, 146MB/s]\n",
      "tokenizer.json: 7.03MB [00:00, 189MB/s]\n",
      "config.json: 100%|█████████████████████████████| 663/663 [00:00<00:00, 5.66MB/s]\n",
      "2025-12-28 00:21:19.807418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-12-28 00:21:19.807418: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766881280.267974     118 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1766881280.268103     119 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1766881280.394345     119 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "E0000 00:00:1766881280.394358     118 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1766881281.514461     118 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766881281.514475     119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766881281.514497     118 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766881281.514500     119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766881281.514507     119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766881281.514505     118 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766881281.514510     119 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1766881281.514514     118 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "model.safetensors.index.json: 27.8kB [00:00, 72.5MB/s]\n",
      "Fetching 4 files:   0%|                                   | 0/4 [00:00<?, ?it/s]\n",
      "model-00004-of-00004.safetensors:   0%|             | 0.00/3.56G [00:00<?, ?B/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|             | 0.00/3.95G [00:00<?, ?B/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   0%|             | 0.00/3.86G [00:00<?, ?B/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:   0%| | 8.13k/3.56G [00:00<119:48:06, 8.25kB/s\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%| | 19.3k/3.95G [00:01<62:20:20, 17.6kB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 1.14M/3.95G [00:01<50:41, 1.30MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 2.30M/3.95G [00:01<24:37, 2.67MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 4.24M/3.95G [00:01<12:19, 5.33MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   0%|    | 390k/3.56G [00:01<2:59:06, 331kB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   0%|    | 7.15M/3.86G [00:01<13:22, 4.80MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 5.65M/3.95G [00:01<12:47, 5.13MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   1%|    | 36.5M/3.86G [00:01<02:30, 25.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 7.88M/3.95G [00:01<08:39, 7.57MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   0%|    | 9.95M/3.95G [00:01<06:45, 9.71MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 24.6M/3.95G [00:02<02:17, 28.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 29.3M/3.95G [00:02<02:16, 28.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 34.6M/3.95G [00:02<02:03, 31.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 38.4M/3.95G [00:02<02:09, 30.3MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   0%|    | 11.3M/3.56G [00:02<11:45, 5.02MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   1%|    | 43.4M/3.86G [00:02<04:16, 14.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|    | 29.2M/3.86G [00:03<06:40, 9.57MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   1%|    | 46.0M/3.95G [00:03<02:52, 22.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   1%|    | 47.5M/3.86G [00:03<05:56, 10.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   1%|    | 53.7M/3.86G [00:04<05:57, 10.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   2%|    | 69.8M/3.86G [00:04<03:16, 19.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|    | 59.4M/3.95G [00:04<05:44, 11.3MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   2%|    | 82.9M/3.86G [00:05<03:08, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   3%|    | 97.4M/3.86G [00:05<02:27, 25.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|    | 42.4M/3.86G [00:05<09:00, 7.07MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:   2%|    | 78.3M/3.56G [00:05<03:27, 16.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   4%|▏    | 165M/3.86G [00:05<00:58, 63.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|    | 45.9M/3.86G [00:06<08:37, 7.38MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   5%|▏    | 180M/3.86G [00:06<01:03, 58.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|    | 61.8M/3.95G [00:06<09:22, 6.90MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   5%|▎    | 205M/3.86G [00:06<01:02, 58.8MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|    | 63.8M/3.95G [00:06<10:23, 6.23MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   7%|▍     | 289M/3.86G [00:07<00:35, 102MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   8%|▍    | 308M/3.86G [00:07<00:35, 99.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:   9%|▌     | 348M/3.86G [00:07<00:29, 118MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   1%|    | 52.3M/3.86G [00:07<10:18, 6.16MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|    | 67.2M/3.95G [00:07<11:10, 5.79MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:   5%|▏    | 174M/3.56G [00:07<01:53, 29.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|    | 78.9M/3.95G [00:07<05:36, 11.5MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  10%|▌     | 396M/3.86G [00:07<00:24, 140MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:   8%|▍    | 274M/3.56G [00:07<01:00, 54.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|    | 84.4M/3.95G [00:07<04:55, 13.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  12%|▋     | 483M/3.86G [00:08<00:23, 142MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   3%|▏    | 119M/3.86G [00:08<02:42, 23.0MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  11%|▌    | 374M/3.56G [00:08<00:41, 76.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   2%|    | 88.0M/3.95G [00:08<05:50, 11.0MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   4%|▏    | 143M/3.86G [00:09<02:29, 25.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  13%|▋    | 517M/3.86G [00:09<00:35, 94.1MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  12%|▌    | 442M/3.56G [00:09<00:39, 78.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   3%|▏    | 115M/3.95G [00:09<03:25, 18.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  16%|▉     | 613M/3.86G [00:09<00:25, 128MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▏    | 183M/3.95G [00:10<01:43, 36.4MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  14%|▋    | 487M/3.56G [00:10<00:54, 56.1MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   5%|▎    | 207M/3.86G [00:11<02:10, 28.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  18%|▉    | 690M/3.86G [00:11<00:44, 71.1MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  15%|▋    | 520M/3.56G [00:11<00:57, 53.1MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   8%|▍    | 299M/3.86G [00:11<01:12, 49.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  19%|▉    | 723M/3.86G [00:11<00:41, 75.2MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   5%|▎    | 216M/3.95G [00:12<02:05, 29.6MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:   9%|▍    | 366M/3.86G [00:12<00:54, 64.2MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  17%|▊    | 587M/3.56G [00:12<00:44, 66.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▎    | 221M/3.95G [00:12<02:10, 28.5MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  18%|▉    | 654M/3.56G [00:12<00:37, 76.9MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  10%|▌    | 397M/3.86G [00:13<01:03, 54.6MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  20%|█    | 721M/3.56G [00:13<00:30, 92.5MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  20%|█    | 776M/3.86G [00:13<00:52, 59.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  11%|▌    | 414M/3.86G [00:13<01:07, 51.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  23%|█▏   | 872M/3.86G [00:13<00:32, 90.7MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  23%|█▏   | 814M/3.56G [00:14<00:27, 98.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  24%|█▏   | 927M/3.86G [00:14<00:40, 73.2MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▎    | 224M/3.95G [00:14<04:44, 13.1MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  24%|█▏   | 871M/3.56G [00:15<00:36, 73.5MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  12%|▌    | 481M/3.86G [00:15<01:26, 39.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  28%|█▏  | 1.09G/3.86G [00:16<00:31, 88.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  29%|█▏  | 1.12G/3.86G [00:16<00:34, 79.5MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   6%|▎    | 227M/3.95G [00:16<07:39, 8.10MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  26%|█▎   | 907M/3.56G [00:17<01:02, 42.5MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  14%|▋    | 548M/3.86G [00:18<01:51, 29.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  31%|█▏  | 1.19G/3.86G [00:19<00:56, 47.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  15%|▊    | 594M/3.86G [00:20<01:47, 30.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  16%|▊    | 602M/3.86G [00:20<01:49, 29.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   7%|▎    | 281M/3.95G [00:20<05:36, 10.9MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  27%|█▎   | 974M/3.56G [00:21<01:21, 31.5MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  16%|▊    | 610M/3.86G [00:21<01:52, 28.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  33%|█▎  | 1.28G/3.86G [00:21<00:53, 48.2MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  29%|█▏  | 1.04G/3.56G [00:22<01:06, 37.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  35%|█▍  | 1.35G/3.86G [00:22<00:42, 58.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▍    | 329M/3.95G [00:22<03:52, 15.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:   8%|▍    | 332M/3.95G [00:22<03:48, 15.8MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  37%|█▍  | 1.42G/3.86G [00:22<00:35, 68.3MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  31%|█▏  | 1.11G/3.56G [00:23<00:58, 42.2MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|▉    | 677M/3.86G [00:23<01:48, 29.4MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  33%|█▎  | 1.18G/3.56G [00:23<00:40, 59.0MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  18%|▉    | 686M/3.86G [00:23<01:50, 28.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌    | 400M/3.95G [00:24<02:27, 24.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌    | 404M/3.95G [00:24<02:28, 23.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌    | 410M/3.95G [00:24<02:32, 23.2MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  38%|█▌  | 1.49G/3.86G [00:24<00:46, 51.5MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  35%|█▍  | 1.25G/3.56G [00:25<00:48, 47.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  40%|█▌  | 1.55G/3.86G [00:25<00:42, 54.0MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  10%|▌    | 413M/3.95G [00:26<04:06, 14.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▌    | 415M/3.95G [00:26<04:16, 13.8MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  36%|█▍  | 1.27G/3.56G [00:26<00:54, 41.9MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  19%|▉    | 753M/3.86G [00:28<02:35, 20.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  20%|▉    | 767M/3.86G [00:28<02:33, 20.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  42%|█▋  | 1.62G/3.86G [00:29<01:05, 34.4MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  38%|█▌  | 1.34G/3.56G [00:31<01:26, 25.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  44%|█▋  | 1.69G/3.86G [00:31<00:59, 36.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▌    | 416M/3.95G [00:31<14:17, 4.12MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▌    | 418M/3.95G [00:31<13:41, 4.30MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▌    | 421M/3.95G [00:31<11:57, 4.91MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|█    | 840M/3.86G [00:31<02:14, 22.5MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  41%|█▋  | 1.47G/3.56G [00:31<00:45, 45.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  45%|█▊  | 1.75G/3.86G [00:32<00:48, 43.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▌    | 429M/3.95G [00:32<08:26, 6.94MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▌    | 431M/3.95G [00:32<07:43, 7.58MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  47%|█▉  | 1.82G/3.86G [00:32<00:40, 50.8MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  43%|█▋  | 1.54G/3.56G [00:32<00:42, 47.8MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  22%|█    | 857M/3.86G [00:33<02:34, 19.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  48%|█▉  | 1.87G/3.86G [00:33<00:35, 55.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  11%|▌    | 433M/3.95G [00:33<11:51, 4.94MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  45%|█▊  | 1.61G/3.56G [00:33<00:35, 55.7MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  23%|█▏   | 883M/3.86G [00:33<02:07, 23.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  49%|█▉  | 1.90G/3.86G [00:33<00:33, 58.2MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  47%|█▊  | 1.66G/3.56G [00:33<00:28, 66.0MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 908M/3.86G [00:34<01:59, 24.8MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▋    | 501M/3.95G [00:34<02:24, 23.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▋    | 508M/3.95G [00:34<02:16, 25.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▋    | 515M/3.95G [00:35<02:05, 27.4MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▋    | 521M/3.95G [00:35<01:57, 29.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  52%|██  | 2.02G/3.86G [00:35<00:26, 69.0MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▋    | 526M/3.95G [00:35<01:57, 29.1MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 927M/3.86G [00:35<02:02, 23.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  13%|▋    | 530M/3.95G [00:35<02:59, 19.0MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  49%|█▉  | 1.75G/3.56G [00:36<00:33, 54.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▋    | 550M/3.95G [00:36<01:50, 30.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  14%|▋    | 559M/3.95G [00:37<02:39, 21.3MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  52%|██  | 1.85G/3.56G [00:37<00:26, 63.9MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  24%|█▏   | 942M/3.86G [00:38<03:34, 13.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▋    | 574M/3.95G [00:38<03:50, 14.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  54%|██▏ | 2.09G/3.86G [00:39<00:51, 34.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  15%|▋    | 588M/3.95G [00:39<04:12, 13.3MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  25%|█▎   | 973M/3.86G [00:41<03:41, 13.0MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  54%|██▏ | 1.92G/3.56G [00:41<00:44, 37.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  56%|██▏ | 2.15G/3.86G [00:42<00:57, 30.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  27%|█   | 1.04G/3.86G [00:42<02:13, 21.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  28%|█   | 1.07G/3.86G [00:43<02:02, 22.8MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  56%|██▏ | 1.99G/3.56G [00:43<00:44, 35.5MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  57%|██▎ | 2.22G/3.86G [00:44<00:50, 32.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  28%|█▏  | 1.09G/3.86G [00:44<02:05, 22.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  59%|██▎ | 2.28G/3.86G [00:44<00:39, 39.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  61%|██▍ | 2.35G/3.86G [00:45<00:30, 49.7MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  57%|██▎ | 2.03G/3.56G [00:45<00:48, 31.5MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  29%|█▏  | 1.12G/3.86G [00:45<02:06, 21.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  62%|██▍ | 2.41G/3.86G [00:45<00:24, 58.8MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  64%|██▌ | 2.48G/3.86G [00:46<00:19, 69.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  66%|██▋ | 2.55G/3.86G [00:46<00:14, 93.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  32%|█▎  | 1.25G/3.86G [00:46<00:56, 46.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  36%|█▍  | 1.38G/3.86G [00:47<00:34, 71.3MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  68%|██▋ | 2.61G/3.86G [00:49<00:22, 54.6MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  39%|█▌  | 1.50G/3.86G [00:49<00:36, 64.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|▊    | 656M/3.95G [00:50<07:20, 7.47MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  69%|██▊ | 2.68G/3.86G [00:50<00:24, 48.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|▊    | 660M/3.95G [00:51<07:14, 7.56MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  41%|█▋  | 1.57G/3.86G [00:51<00:41, 54.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  17%|▊    | 663M/3.95G [00:51<07:26, 7.36MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  59%|██▎ | 2.10G/3.56G [00:51<01:13, 19.8MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  44%|█▊  | 1.71G/3.86G [00:52<00:26, 80.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  71%|██▊ | 2.75G/3.86G [00:54<00:32, 34.4MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  45%|█▊  | 1.73G/3.86G [00:54<00:39, 53.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  18%|▉    | 693M/3.95G [00:54<06:04, 8.92MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  73%|██▉ | 2.81G/3.86G [00:54<00:24, 42.8MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  19%|▉    | 761M/3.95G [00:54<02:43, 19.4MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  48%|█▉  | 1.86G/3.86G [00:55<00:28, 70.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  75%|██▉ | 2.88G/3.86G [00:55<00:18, 52.6MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  61%|██▍ | 2.17G/3.56G [00:55<01:10, 19.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  76%|███ | 2.95G/3.86G [00:55<00:12, 71.1MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  51%|██  | 1.99G/3.86G [00:56<00:22, 84.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  78%|███ | 3.02G/3.86G [00:56<00:13, 63.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  20%|▉    | 787M/3.95G [00:57<03:30, 15.0MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  63%|██▌ | 2.24G/3.56G [00:57<01:01, 21.3MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  80%|███▏| 3.08G/3.86G [00:58<00:13, 60.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  53%|██▏ | 2.06G/3.86G [00:58<00:28, 62.5MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  64%|██▌ | 2.26G/3.56G [00:58<00:57, 22.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|█    | 812M/3.95G [00:58<03:12, 16.2MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  55%|██▏ | 2.13G/3.86G [00:59<00:27, 64.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  81%|███▎| 3.15G/3.86G [00:59<00:12, 55.5MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  21%|█    | 838M/3.95G [01:00<03:01, 17.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  83%|███▎| 3.19G/3.86G [01:00<00:13, 49.8MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  64%|██▌ | 2.29G/3.56G [01:01<01:08, 18.6MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  57%|██▎ | 2.20G/3.86G [01:01<00:35, 47.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█    | 864M/3.95G [01:02<03:22, 15.3MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  84%|███▍| 3.26G/3.86G [01:02<00:14, 42.0MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  22%|█    | 878M/3.95G [01:03<03:36, 14.2MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  59%|██▎ | 2.27G/3.86G [01:04<00:40, 39.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  86%|███▍| 3.33G/3.86G [01:04<00:13, 40.8MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  66%|██▋ | 2.36G/3.56G [01:04<01:04, 18.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  88%|███▌| 3.40G/3.86G [01:06<00:11, 39.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  59%|██▎ | 2.28G/3.86G [01:06<00:54, 29.2MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  61%|██▍ | 2.36G/3.86G [01:06<00:33, 44.7MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  23%|█▏   | 912M/3.95G [01:07<04:19, 11.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  90%|███▌| 3.46G/3.86G [01:07<00:09, 44.4MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█▎   | 992M/3.95G [01:08<02:04, 23.7MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  63%|██▌ | 2.45G/3.86G [01:08<00:29, 47.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  25%|█   | 1.00G/3.95G [01:08<01:59, 24.6MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  91%|███▋| 3.53G/3.86G [01:09<00:07, 42.9MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  68%|██▋ | 2.42G/3.56G [01:09<01:06, 16.9MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  65%|██▌ | 2.51G/3.86G [01:09<00:27, 48.5MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  70%|██▊ | 2.49G/3.56G [01:09<00:43, 24.6MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  71%|██▊ | 2.53G/3.56G [01:10<00:37, 27.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  27%|█   | 1.07G/3.95G [01:11<02:01, 23.7MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  93%|███▋| 3.60G/3.86G [01:11<00:07, 35.9MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  72%|██▉ | 2.58G/3.56G [01:11<00:34, 28.8MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  67%|██▋ | 2.58G/3.86G [01:12<00:32, 39.2MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  73%|██▉ | 2.58G/3.56G [01:13<00:39, 24.4MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  95%|███▊| 3.66G/3.86G [01:13<00:05, 35.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|█▏  | 1.14G/3.95G [01:14<01:55, 24.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  29%|█▏  | 1.15G/3.95G [01:14<01:50, 25.2MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  68%|██▋ | 2.61G/3.86G [01:15<00:46, 26.8MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|█▏  | 1.17G/3.95G [01:15<01:53, 24.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  30%|█▏  | 1.20G/3.95G [01:15<01:25, 32.2MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  75%|██▉ | 2.65G/3.56G [01:15<00:37, 24.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  31%|█▎  | 1.24G/3.95G [01:17<01:33, 28.9MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  76%|███ | 2.72G/3.56G [01:17<00:29, 28.1MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  97%|███▊| 3.73G/3.86G [01:18<00:05, 23.5MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  78%|███▏| 2.79G/3.56G [01:19<00:23, 32.9MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  33%|█▎  | 1.31G/3.95G [01:19<01:25, 31.0MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  69%|██▊ | 2.68G/3.86G [01:19<00:54, 21.9MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  79%|███▏| 2.82G/3.56G [01:19<00:19, 37.5MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  80%|███▏| 2.84G/3.56G [01:19<00:17, 42.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  35%|█▍  | 1.38G/3.95G [01:19<00:59, 43.1MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  71%|██▊ | 2.75G/3.86G [01:19<00:37, 30.1MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▍  | 1.42G/3.95G [01:20<00:48, 51.8MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  81%|███▏| 2.87G/3.56G [01:20<00:16, 42.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  36%|█▍  | 1.44G/3.95G [01:20<00:47, 52.8MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  82%|███▎| 2.93G/3.56G [01:20<00:11, 54.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  37%|█▍  | 1.47G/3.95G [01:20<00:46, 53.0MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  83%|███▎| 2.96G/3.56G [01:21<00:10, 56.2MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  84%|███▎| 2.98G/3.56G [01:21<00:10, 55.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|█▌  | 1.49G/3.95G [01:21<00:58, 42.1MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  38%|█▌  | 1.50G/3.95G [01:22<00:58, 41.4MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  39%|█▌  | 1.53G/3.95G [01:23<01:11, 33.9MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  73%|██▉ | 2.82G/3.86G [01:25<00:51, 20.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  40%|█▌  | 1.58G/3.95G [01:25<01:31, 25.9MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  86%|███▍| 3.04G/3.56G [01:26<00:22, 23.3MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  74%|██▉ | 2.87G/3.86G [01:26<00:40, 24.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  42%|█▋  | 1.64G/3.95G [01:26<01:02, 36.6MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  43%|█▋  | 1.71G/3.95G [01:26<00:38, 57.8MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  76%|███ | 2.94G/3.86G [01:27<00:29, 31.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  45%|█▊  | 1.78G/3.95G [01:27<00:32, 66.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  47%|█▊  | 1.84G/3.95G [01:27<00:24, 86.3MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  87%|███▍| 3.11G/3.56G [01:28<00:15, 28.0MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  79%|███▏| 3.06G/3.86G [01:28<00:18, 44.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  48%|█▉  | 1.91G/3.95G [01:31<00:47, 42.7MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  89%|███▌| 3.18G/3.56G [01:31<00:14, 25.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  49%|█▉  | 1.95G/3.95G [01:32<00:51, 38.8MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  81%|███▎| 3.15G/3.86G [01:32<00:21, 33.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  51%|██  | 2.01G/3.95G [01:33<00:46, 41.6MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  83%|███▎| 3.21G/3.86G [01:34<00:17, 37.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  53%|██  | 2.08G/3.95G [01:34<00:32, 57.8MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  91%|███▋| 3.25G/3.56G [01:34<00:12, 24.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  54%|██▏ | 2.15G/3.95G [01:34<00:25, 71.0MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  85%|███▍| 3.28G/3.86G [01:34<00:13, 44.9MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  87%|███▍| 3.35G/3.86G [01:34<00:08, 60.6MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  93%|███▋| 3.29G/3.56G [01:35<00:09, 28.8MB/s]\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors:  98%|███▉| 3.80G/3.86G [01:35<00:02, 23.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00002-of-00004.safetensors: 100%|████| 3.86G/3.86G [01:35<00:00, 40.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  56%|██▏ | 2.22G/3.95G [01:35<00:25, 67.1MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  88%|███▌| 3.41G/3.86G [01:35<00:07, 60.8MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  57%|██▎ | 2.27G/3.95G [01:36<00:20, 80.9MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  90%|███▌| 3.46G/3.86G [01:36<00:05, 74.3MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  59%|██▉  | 2.34G/3.95G [01:36<00:14, 113MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  91%|███▋| 3.53G/3.86G [01:36<00:04, 80.6MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  61%|██▍ | 2.39G/3.95G [01:37<00:23, 67.7MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  93%|███▋| 3.60G/3.86G [01:38<00:03, 68.0MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  95%|███▊| 3.66G/3.86G [01:39<00:03, 54.0MB/s]\u001b[A\u001b[A\n",
      "model-00004-of-00004.safetensors:  94%|███▊| 3.36G/3.56G [01:40<00:09, 20.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  62%|██▍ | 2.45G/3.95G [01:40<00:31, 46.8MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  96%|███▊| 3.42G/3.56G [01:41<00:05, 24.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  64%|██▌ | 2.52G/3.95G [01:42<00:37, 38.2MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  97%|███▊| 3.73G/3.86G [01:43<00:03, 35.9MB/s]\u001b[A\u001b[A\n",
      "model-00001-of-00004.safetensors:  66%|██▌ | 2.59G/3.95G [01:44<00:39, 34.5MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors:  98%|███▉| 3.49G/3.56G [01:44<00:02, 23.0MB/s]\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors:  98%|███▉| 3.80G/3.86G [01:44<00:01, 36.5MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00003-of-00004.safetensors: 100%|████| 3.86G/3.86G [01:45<00:00, 36.7MB/s]\u001b[A\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  67%|██▋ | 2.66G/3.95G [01:45<00:30, 41.9MB/s]\u001b[A\n",
      "model-00004-of-00004.safetensors: 100%|████| 3.56G/3.56G [01:45<00:00, 33.6MB/s]\u001b[A\n",
      "\n",
      "model-00001-of-00004.safetensors:  69%|██▊ | 2.72G/3.95G [01:46<00:23, 51.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  70%|██▊ | 2.76G/3.95G [01:46<00:20, 57.7MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  73%|███▋ | 2.89G/3.95G [01:46<00:10, 102MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  75%|███▋ | 2.96G/3.95G [01:47<00:09, 102MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  78%|███▉ | 3.09G/3.95G [01:47<00:05, 151MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  80%|████ | 3.16G/3.95G [01:48<00:05, 157MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  82%|████ | 3.23G/3.95G [01:49<00:05, 134MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  83%|████▏| 3.29G/3.95G [01:49<00:05, 121MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  85%|████▎| 3.36G/3.95G [01:50<00:05, 110MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  86%|███▍| 3.41G/3.95G [01:51<00:05, 98.2MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  88%|███▌| 3.48G/3.95G [01:52<00:06, 71.0MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  90%|███▌| 3.54G/3.95G [01:54<00:06, 60.3MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  92%|███▋| 3.61G/3.95G [01:55<00:05, 64.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  93%|███▋| 3.68G/3.95G [01:55<00:03, 78.8MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  95%|███▊| 3.74G/3.95G [01:56<00:02, 89.5MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  97%|████▊| 3.81G/3.95G [01:56<00:01, 108MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors:  98%|████▉| 3.88G/3.95G [01:56<00:00, 135MB/s]\u001b[A\n",
      "model-00001-of-00004.safetensors: 100%|████| 3.95G/3.95G [01:56<00:00, 33.8MB/s]\u001b[A\n",
      "Fetching 4 files: 100%|███████████████████████████| 4/4 [01:57<00:00, 29.30s/it]\n",
      "Fetching 4 files: 100%|███████████████████████████| 4/4 [01:57<00:00, 29.31s/it]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:06<00:00, 16.71s/it]\n",
      "generation_config.json: 100%|██████████████████| 243/243 [00:00<00:00, 1.38MB/s]\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:07<00:00, 16.76s/it]\n",
      "  0%|                                                   | 0/231 [00:00<?, ?it/s]The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p', 'top_k']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      " 35%|████████████▊                        | 80/231 [3:42:51<7:06:25, 169.44s/it]"
     ]
    }
   ],
   "source": [
    "!torchrun --nproc_per_node=2 main.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from report_generation import generate_missing_affiliation_report\n",
    "generate_missing_affiliation_report()\n",
    "\n",
    "!cat /kaggle/working/missing_affiliations_reports.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 9133727,
     "sourceId": 14314816,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
