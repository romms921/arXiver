title,abstract,authors,published,link,category,summary,keywords,affiliation
Computing with D-Algebraic Sequences,"A sequence is difference algebraic (or D-algebraic) if finitely many shifts
of its general term satisfy a polynomial relationship; that is, they are the
coordinates of a generic point on an affine hypersurface. The corresponding
equations are called algebraic difference equations (ADE). We show that
subsequences of D-algebraic sequences, indexed by arithmetic progressions,
satisfy ADEs of the same orders as the original sequences. Additionally, we
provide algorithms for operations with D-algebraic sequences and discuss the
difference-algebraic nature of holonomic and $C^2$-finite sequences.",Bertrand Teguia Tabuguia,2024-12-30,http://arxiv.org/abs/2412.20630v1,math.AG,"The abstract discusses the properties of difference algebraic sequences, particularly that subsequences indexed by arithmetic progressions satisfy algebraic difference equations of the same order as the original sequences.",Sequences D-Algebraic Computing,['']
Slow Perception: Let's Perceive Geometric Figures Step-by-step,"Recently, ""visual o1"" began to enter people's vision, with expectations that
this slow-thinking design can solve visual reasoning tasks, especially
geometric math problems. However, the reality is that current LVLMs (Large
Vision Language Models) can hardly even accurately copy a geometric figure, let
alone truly understand the complex inherent logic and spatial relationships
within geometric shapes. We believe accurate copying (strong perception) is the
first step to visual o1. Accordingly, we introduce the concept of ""slow
perception"" (SP), which guides the model to gradually perceive basic point-line
combinations, as our humans, reconstruct complex geometric structures
progressively. There are two-fold stages in SP: a) perception decomposition.
Perception is not instantaneous. In this stage, complex geometric figures are
broken down into basic simple units to unify geometry representation. b)
perception flow, which acknowledges that accurately tracing a line is not an
easy task. This stage aims to avoid ""long visual jumps"" in regressing line
segments by using a proposed ""perceptual ruler"" to trace each line
stroke-by-stroke. Surprisingly, such a human-like perception manner enjoys an
inference time scaling law -- the slower, the better. Researchers strive to
speed up the model's perception in the past, but we slow it down again,
allowing the model to read the image step-by-step and carefully.","Haoran Wei, Youyang Yin, Yumeng Li, Jia Wang, Liang Zhao, Jianjian Sun, Zheng Ge, Xiangyu Zhang",2024-12-30,http://arxiv.org/abs/2412.20631v1,cs.CV,"Researchers introduce ""slow perception"" (SP) to improve visual reasoning tasks, particularly geometric math problems, by guiding the model to gradually perceive basic point-line combinations, decomposing complex figures into simple units, and tracing lines stroke-by-stroke.",slow perception geometric figures,
EVOLVE: Emotion and Visual Output Learning via LLM Evaluation,"Human acceptance of social robots is greatly effected by empathy and
perceived understanding. This necessitates accurate and flexible responses to
various input data from the user. While systems such as this can become
increasingly complex as more states or response types are included, new
research in the application of large language models towards human-robot
interaction has allowed for more streamlined perception and reaction pipelines.
LLM-selected actions and emotional expressions can help reinforce the realism
of displayed empathy and allow for improved communication between the robot and
user. Beyond portraying empathy in spoken or written responses, this shows the
possibilities of using LLMs in actuated, real world scenarios. In this work we
extend research in LLM-driven nonverbal behavior for social robots by
considering more open-ended emotional response selection leveraging new
advances in vision-language models, along with emotionally aligned motion and
color pattern selections that strengthen conveyance of meaning and empathy.","Jordan Sinclair, Christopher Reardon",2024-12-30,http://arxiv.org/abs/2412.20632v1,cs.RO,"The paper explores the use of large language models to improve social robots' empathetic communication by selecting accurate and flexible responses, incorporating nonverbal behaviors, and utilizing vision-language models for emotional response selection.","Emotion, Learning, LLM",
"Graph Neural Networks for Next-Generation-IoT: Recent Advances and Open
  Challenges","Graph Neural Networks (GNNs) have emerged as a critical tool for optimizing
and managing the complexities of the Internet of Things (IoT) in
next-generation networks. This survey presents a comprehensive exploration of
how GNNs may be harnessed in 6G IoT environments, focusing on key challenges
and opportunities through a series of open questions. We commence with an
exploration of GNN paradigms and the roles of node, edge, and graph-level tasks
in solving wireless networking problems and highlight GNNs' ability to overcome
the limitations of traditional optimization methods. This guidance enhances
problem-solving efficiency across various next-generation (NG) IoT scenarios.
Next, we provide a detailed discussion of the application of GNN in advanced NG
enabling technologies, including massive MIMO, reconfigurable intelligent
surfaces, satellites, THz, mobile edge computing (MEC), and ultra-reliable low
latency communication (URLLC). We then delve into the challenges posed by
adversarial attacks, offering insights into defense mechanisms to secure
GNN-based NG-IoT networks. Next, we examine how GNNs can be integrated with
future technologies like integrated sensing and communication (ISAC),
satellite-air-ground-sea integrated networks (SAGSIN), and quantum computing.
Our findings highlight the transformative potential of GNNs in improving
efficiency, scalability, and security within NG-IoT systems, paving the way for
future advances. Finally, we propose a set of design guidelines to facilitate
the development of efficient, scalable, and secure GNN models tailored for NG
IoT applications.","Nguyen Xuan Tung, Le Tung Giang, Bui Duc Son, Seon Geun Jeong, Trinh Van Chien, Won Joo Hwang, Lajos Hanzo",2024-12-30,http://arxiv.org/abs/2412.20634v1,cs.IT,"This survey explores the potential of Graph Neural Networks (GNNs) in 6G Internet of Things (IoT) environments, highlighting their ability to overcome traditional optimization methods' limitations, and discussing applications, challenges, and future directions.",Graph Neural Networks IoT Advances Challenges,
"NetFlowGen: Leveraging Generative Pre-training for Network Traffic
  Dynamics","Understanding the traffic dynamics in networks is a core capability for
automated systems to monitor and analyze networking behaviors, reducing
expensive human efforts and economic risks through tasks such as traffic
classification, congestion prediction, and attack detection. However, it is
still challenging to accurately model network traffic with machine learning
approaches in an efficient and broadly applicable manner. Task-specific models
trained from scratch are used for different networking applications, which
limits the efficiency of model development and generalization of model
deployment. Furthermore, while networking data is abundant, high-quality
task-specific labels are often insufficient for training individual models.
Large-scale self-supervised learning on unlabeled data provides a natural
pathway for tackling these challenges. We propose to pre-train a
general-purpose machine learning model to capture traffic dynamics with only
traffic data from NetFlow records, with the goal of fine-tuning for different
downstream tasks with small amount of labels. Our presented NetFlowGen
framework goes beyond a proof-of-concept for network traffic pre-training and
addresses specific challenges such as unifying network feature representations,
learning from large unlabeled traffic data volume, and testing on real
downstream tasks in DDoS attack detection. Experiments demonstrate promising
results of our pre-training framework on capturing traffic dynamics and
adapting to different networking tasks.","Jiawei Zhou, Woojeong Kim, Zhiying Xu, Alexander M. Rush, Minlan Yu",2024-12-30,http://arxiv.org/abs/2412.20635v1,cs.LG,"The NetFlowGen framework proposes a general-purpose machine learning model pre-trained on NetFlow records to capture network traffic dynamics, which can be fine-tuned for different downstream tasks with a small amount of labels.","generative pre-training, network traffic, dynamics",
"Knowledge Editing for Large Language Model with Knowledge Neuronal
  Ensemble","As real-world knowledge is constantly evolving, ensuring the timeliness and
accuracy of a model's knowledge is crucial. This has made knowledge editing in
large language models increasingly important. However, existing knowledge
editing methods face several challenges, including parameter localization
coupling, imprecise localization, and a lack of dynamic interaction across
layers. In this paper, we propose a novel knowledge editing method called
Knowledge Neuronal Ensemble (KNE). A knowledge neuronal ensemble represents a
group of neurons encoding specific knowledge, thus mitigating the issue of
frequent parameter modification caused by coupling in parameter localization.
The KNE method enhances the precision and accuracy of parameter localization by
computing gradient attribution scores for each parameter at each layer. During
the editing process, only the gradients and losses associated with the
knowledge neuronal ensemble are computed, with error backpropagation performed
accordingly, ensuring dynamic interaction and collaborative updates among
parameters. Experimental results on three widely used knowledge editing
datasets show that the KNE method significantly improves the accuracy of
knowledge editing and achieves, or even exceeds, the performance of the best
baseline methods in portability and locality metrics.","Yongchang Li, Yujin Zhu, Tao Yan, Shijian Fan, Gang Wu, Liang Xu",2024-12-30,http://arxiv.org/abs/2412.20637v1,cs.CL,"This paper proposes a novel knowledge editing method called Knowledge Neuronal Ensemble (KNE), which improves the accuracy and precision of parameter localization by computing gradient attribution scores and dynamically interacting among parameters.",Knowledge Neural,
Predicting Long Term Sequential Policy Value Using Softer Surrogates,"Performing policy evaluation in education, healthcare and online commerce can
be challenging, because it can require waiting substantial amounts of time to
observe outcomes over the desired horizon of interest. While offline evaluation
methods can be used to estimate the performance of a new decision policy from
historical data in some cases, such methods struggle when the new policy
involves novel actions or is being run in a new decision process with
potentially different dynamics. Here we consider how to estimate the
full-horizon value of a new decision policy using only short-horizon data from
the new policy, and historical full-horizon data from a different behavior
policy. We introduce two new estimators for this setting, including a doubly
robust estimator, and provide formal analysis of their properties. Our
empirical results on two realistic simulators, of HIV treatment and sepsis
treatment, show that our methods can often provide informative estimates of a
new decision policy ten times faster than waiting for the full horizon,
highlighting that it may be possible to quickly identify if a new decision
policy, involving new actions, is better or worse than existing past policies.","Hyunji Nam, Allen Nie, Ge Gao, Vasilis Syrgkanis, Emma Brunskill",2024-12-30,http://arxiv.org/abs/2412.20638v1,cs.AI,Researchers propose two new estimators to evaluate the performance of a new decision policy using short-horizon data from the new policy and historical full-horizon data from a different behavior policy.,Sequential Policy Value Softer Surrogates,
"SafeSynthDP: Leveraging Large Language Models for Privacy-Preserving
  Synthetic Data Generation Using Differential Privacy","Machine learning (ML) models frequently rely on training data that may
include sensitive or personal information, raising substantial privacy
concerns. Legislative frameworks such as the General Data Protection Regulation
(GDPR) and the California Consumer Privacy Act (CCPA) have necessitated the
development of strategies that preserve privacy while maintaining the utility
of data. In this paper, we investigate the capability of Large Language Models
(LLMs) to generate synthetic datasets integrated with Differential Privacy (DP)
mechanisms, thereby enabling data-driven research and model training without
direct exposure of sensitive information. Our approach incorporates DP-based
noise injection methods, including Laplace and Gaussian distributions, into the
data generation process. We then evaluate the utility of these DP-enhanced
synthetic datasets by comparing the performance of ML models trained on them
against models trained on the original data. To substantiate privacy
guarantees, we assess the resilience of the generated synthetic data to
membership inference attacks and related threats. The experimental results
demonstrate that integrating DP within LLM-driven synthetic data generation
offers a viable balance between privacy protection and data utility. This study
provides a foundational methodology and insight into the privacy-preserving
capabilities of LLMs, paving the way for compliant and effective ML research
and applications.","Md Mahadi Hasan Nahid, Sadid Bin Hasan",2024-12-30,http://arxiv.org/abs/2412.20641v1,cs.LG,The paper investigates the use of large language models to generate synthetic datasets with differential privacy mechanisms to preserve privacy while maintaining data utility for machine learning research and applications.,"Large Language Models, Synthetic Data, Differential Privacy",
Uncertainty Herding: One Active Learning Method for All Label Budgets,"Most active learning research has focused on methods which perform well when
many labels are available, but can be dramatically worse than random selection
when label budgets are small. Other methods have focused on the low-budget
regime, but do poorly as label budgets increase. As the line between ""low"" and
""high"" budgets varies by problem, this is a serious issue in practice. We
propose uncertainty coverage, an objective which generalizes a variety of low-
and high-budget objectives, as well as natural, hyperparameter-light methods to
smoothly interpolate between low- and high-budget regimes. We call greedy
optimization of the estimate Uncertainty Herding; this simple method is
computationally fast, and we prove that it nearly optimizes the
distribution-level coverage. In experimental validation across a variety of
active learning tasks, our proposal matches or beats state-of-the-art
performance in essentially all cases; it is the only method of which we are
aware that reliably works well in both low- and high-budget settings.","Wonho Bae, Gabriel L. Oliveira, Danica J. Sutherland",2024-12-30,http://arxiv.org/abs/2412.20644v1,cs.LG,"Uncertainty coverage, a new active learning objective, generalizes various objectives and can smoothly interpolate between low- and high-budget regimes, outperforming current methods in both settings.",uncertainty herding active learning,
YOLO-UniOW: Efficient Universal Open-World Object Detection,"Traditional object detection models are constrained by the limitations of
closed-set datasets, detecting only categories encountered during training.
While multimodal models have extended category recognition by aligning text and
image modalities, they introduce significant inference overhead due to
cross-modality fusion and still remain restricted by predefined vocabulary,
leaving them ineffective at handling unknown objects in open-world scenarios.
In this work, we introduce Universal Open-World Object Detection (Uni-OWD), a
new paradigm that unifies open-vocabulary and open-world object detection
tasks. To address the challenges of this setting, we propose YOLO-UniOW, a
novel model that advances the boundaries of efficiency, versatility, and
performance. YOLO-UniOW incorporates Adaptive Decision Learning to replace
computationally expensive cross-modality fusion with lightweight alignment in
the CLIP latent space, achieving efficient detection without compromising
generalization. Additionally, we design a Wildcard Learning strategy that
detects out-of-distribution objects as ""unknown"" while enabling dynamic
vocabulary expansion without the need for incremental learning. This design
empowers YOLO-UniOW to seamlessly adapt to new categories in open-world
environments. Extensive experiments validate the superiority of YOLO-UniOW,
achieving achieving 34.6 AP and 30.0 APr on LVIS with an inference speed of
69.6 FPS. The model also sets benchmarks on M-OWODB, S-OWODB, and nuScenes
datasets, showcasing its unmatched performance in open-world object detection.
Code and models are available at https://github.com/THU-MIG/YOLO-UniOW.","Lihao Liu, Juexiao Feng, Hui Chen, Ao Wang, Lin Song, Jungong Han, Guiguang Ding",2024-12-30,http://arxiv.org/abs/2412.20645v1,cs.CV,"This paper introduces Universal Open-World Object Detection (Uni-OWD), a paradigm that unifies open-vocabulary and open-world object detection tasks, and presents YOLO-UniOW, a novel model that achieves efficient detection without compromising generalization and adapts to new categories in open-world environments.","Object Detection, Open-World, Efficient",
Enhancing Visual Representation for Text-based Person Searching,"Text-based person search aims to retrieve the matched pedestrians from a
large-scale image database according to the text description. The core
difficulty of this task is how to extract effective details from pedestrian
images and texts, and achieve cross-modal alignment in a common latent space.
Prior works adopt image and text encoders pre-trained on unimodal data to
extract global and local features from image and text respectively, and then
global-local alignment is achieved explicitly. However, these approaches still
lack the ability of understanding visual details, and the retrieval accuracy is
still limited by identity confusion. In order to alleviate the above problems,
we rethink the importance of visual features for text-based person search, and
propose VFE-TPS, a Visual Feature Enhanced Text-based Person Search model. It
introduces a pre-trained multimodal backbone CLIP to learn basic multimodal
features and constructs Text Guided Masked Image Modeling task to enhance the
model's ability of learning local visual details without explicit annotation.
In addition, we design Identity Supervised Global Visual Feature Calibration
task to guide the model learn identity-aware global visual features. The key
finding of our study is that, with the help of our proposed auxiliary tasks,
the knowledge embedded in the pre-trained CLIP model can be successfully
adapted to text-based person search task, and the model's visual understanding
ability is significantly enhanced. Experimental results on three benchmarks
demonstrate that our proposed model exceeds the existing approaches, and the
Rank-1 accuracy is significantly improved with a notable margin of about
$1\%\sim9\%$. Our code can be found at
https://github.com/zhangweifeng1218/VFE_TPS.","Wei Shen, Ming Fang, Yuxia Wang, Jiafeng Xiao, Diping Li, Huangqun Chen, Ling Xu, Weifeng Zhang",2024-12-30,http://arxiv.org/abs/2412.20646v1,cs.CV,"This paper proposes VFE-TPS, a Visual Feature Enhanced Text-based Person Search model that uses a pre-trained multimodal backbone CLIP to learn basic multimodal features and constructs two auxiliary tasks to enhance local visual details and identity-aware global visual features for text-based person search.",Visual representation text-based person searching,
"Latent Drifting in Diffusion Models for Counterfactual Medical Image
  Synthesis","Scaling by training on large datasets has been shown to enhance the quality
and fidelity of image generation and manipulation with diffusion models;
however, such large datasets are not always accessible in medical imaging due
to cost and privacy issues, which contradicts one of the main applications of
such models to produce synthetic samples where real data is scarce. Also,
finetuning on pre-trained general models has been a challenge due to the
distribution shift between the medical domain and the pre-trained models. Here,
we propose Latent Drift (LD) for diffusion models that can be adopted for any
fine-tuning method to mitigate the issues faced by the distribution shift or
employed in inference time as a condition. Latent Drifting enables diffusion
models to be conditioned for medical images fitted for the complex task of
counterfactual image generation, which is crucial to investigate how parameters
such as gender, age, and adding or removing diseases in a patient would alter
the medical images. We evaluate our method on three public longitudinal
benchmark datasets of brain MRI and chest X-rays for counterfactual image
generation. Our results demonstrate significant performance gains in various
scenarios when combined with different fine-tuning schemes. The source code of
this work will be publicly released upon its acceptance.","Yousef Yeganeh, Ioannis Charisiadis, Marta Hasny, Martin Hartenberger, Björn Ommer, Nassir Navab, Azade Farshad, Ehsan Adeli",2024-12-30,http://arxiv.org/abs/2412.20651v1,cs.CV,"The paper proposes Latent Drift (LD) for diffusion models to mitigate the distribution shift between medical domain and pre-trained models, enabling counterfactual image generation in medical imaging.",diffusion models medical image synthesis,
"Impact of Cognitive Load on Human Trust in Hybrid Human-Robot
  Collaboration","Human trust plays a crucial role in the effectiveness of human-robot
collaboration. Despite its significance, the development and maintenance of an
optimal trust level are obstructed by the complex nature of influencing factors
and their mechanisms. This study investigates the effects of cognitive load on
human trust within the context of a hybrid human-robot collaboration task. An
experiment is conducted where the humans and the robot, acting as team members,
collaboratively construct pyramids with differentiated levels of task
complexity. Our findings reveal that cognitive load exerts diverse impacts on
human trust in the robot. Notably, there is an increase in human trust under
conditions of high cognitive load. Furthermore, the rewards for performance are
substantially higher in tasks with high cognitive load compared to those with
low cognitive load, and a significant correlation exists between human trust
and the failure risk of performance in tasks with low and medium cognitive
load. By integrating interdependent task steps, this research emphasizes the
unique dynamics of hybrid human-robot collaboration scenarios. The insights
gained not only contribute to understanding how cognitive load influences trust
but also assist developers in optimizing collaborative target selection and
designing more effective human-robot interfaces in such environments.","Hao Guo, Bangan Wu, Qi Li, Zhen Ding, Feng Jiang, Chunzhi Yi",2024-12-30,http://arxiv.org/abs/2412.20654v1,cs.RO,This study investigates how cognitive load affects human trust in a robot during a collaborative task and finds that high cognitive load increases human trust and is associated with higher performance rewards and failure risk levels.,"Cognitive Load, Human Trust, Collaboration",
Environmental and Economic Impact of I/O Device Obsolescence,"This paper analyzes the proportion of Input/output devices made obsolete by
changes in technology generations. This obsolescence may be by new
software/hardware generations rendering otherwise functional devices unusable.
Concluding with brief analysis on the economic and environmental impacts of the
e-waste produced.","Patrick Gould, Guanqun Song, Ting Zhu",2024-12-30,http://arxiv.org/abs/2412.20655v1,cs.CY,"This paper examines the proportion of input/output devices rendered obsolete by technological advancements, and discusses the economic and environmental consequences of the resulting e-waste.",I/O Device Obsolescence Environmental Economic Impact,
"Overcoming Class Imbalance: Unified GNN Learning with Structural and
  Semantic Connectivity Representations","Class imbalance is pervasive in real-world graph datasets, where the majority
of annotated nodes belong to a small set of classes (majority classes), leaving
many other classes (minority classes) with only a handful of labeled nodes.
Graph Neural Networks (GNNs) suffer from significant performance degradation in
the presence of class imbalance, exhibiting bias towards majority classes and
struggling to generalize effectively on minority classes. This limitation
stems, in part, from the message passing process, leading GNNs to overfit to
the limited neighborhood of annotated nodes from minority classes and impeding
the propagation of discriminative information throughout the entire graph. In
this paper, we introduce a novel Unified Graph Neural Network Learning
(Uni-GNN) framework to tackle class-imbalanced node classification. The
proposed framework seamlessly integrates both structural and semantic
connectivity representations through semantic and structural node encoders. By
combining these connectivity types, Uni-GNN extends the propagation of node
embeddings beyond immediate neighbors, encompassing non-adjacent structural
nodes and semantically similar nodes, enabling efficient diffusion of
discriminative information throughout the graph. Moreover, to harness the
potential of unlabeled nodes within the graph, we employ a balanced
pseudo-label generation mechanism that augments the pool of available labeled
nodes from minority classes in the training set. Experimental results
underscore the superior performance of our proposed Uni-GNN framework compared
to state-of-the-art class-imbalanced graph learning baselines across multiple
benchmark datasets.","Abdullah Alchihabi, Hao Yan, Yuhong Guo",2024-12-30,http://arxiv.org/abs/2412.20656v1,cs.LG,"The Uni-GNN framework is introduced to address class imbalance in graph neural networks, seamlessly integrating structural and semantic connectivity representations to efficiently propagate discriminative information throughout the graph and improve node classification performance.","Class Imbalance, GNN Learning",
"Diffgrasp: Whole-Body Grasping Synthesis Guided by Object Motion Using a
  Diffusion Model","Generating high-quality whole-body human object interaction motion sequences
is becoming increasingly important in various fields such as animation, VR/AR,
and robotics. The main challenge of this task lies in determining the level of
involvement of each hand given the complex shapes of objects in different sizes
and their different motion trajectories, while ensuring strong grasping realism
and guaranteeing the coordination of movement in all body parts. Contrasting
with existing work, which either generates human interaction motion sequences
without detailed hand grasping poses or only models a static grasping pose, we
propose a simple yet effective framework that jointly models the relationship
between the body, hands, and the given object motion sequences within a single
diffusion model. To guide our network in perceiving the object's spatial
position and learning more natural grasping poses, we introduce novel
contact-aware losses and incorporate a data-driven, carefully designed
guidance. Experimental results demonstrate that our approach outperforms the
state-of-the-art method and generates plausible whole-body motion sequences.","Yonghao Zhang, Qiang He, Yanguang Wan, Yinda Zhang, Xiaoming Deng, Cuixia Ma, Hongan Wang",2024-12-30,http://arxiv.org/abs/2412.20657v1,cs.CV,"A novel framework is proposed to generate high-quality whole-body human object interaction motion sequences by jointly modeling the relationship between the body, hands, and object motion sequences within a single diffusion model.",Whole-Body Grasping Synthesis Diffusion Model,
"Nanosatellite Design Considerations for a Mission to Explore the
  Propellant Sloshing Problem","Sloshing Platform for In-Orbit Controller Experimentation is an ambitious,
student run mission to design and fly a cubesat to study fluid sloshing in
spacecraft. The project will examine zero-g propellant sloshing from an
experimental standpoint. Despite the small size and limited payload capacity,
we intend to use the cubesat platform to mimic larger spacecraft and implement
novel detection and computer vision methods in our analysis. Many modern
spacecraft rely on propellant-filled tanks to perform attitude control and
station-keeping maneuvers. When a large percentage of the spacecraft's mass is
comprised of liquid propellant, sloshing becomes a critical aspect of
spacecraft attitude control and stability. The mission will study the
tank/fluid dynamics using new methods to gain an enhanced understanding of
low-gravity fluid disturbance effects and improve simulations using equivalent
mechanical models (EMMs). Active control of the fluid leading to the reduction
of propellant slosh settling times will improve the maneuverability and
performance of spacecraft. This paper will focus on satellite payload research
and design requirements used to inform other aspects of the SPICEsat design. In
this paper, mission objectives will be discussed, numerical simulations for the
proposed control algorithms are demonstrated, and a satellite experiment design
is presented. Finally, we examine computational fluid dynamics models to
validate the satellite design and propellant sensing components of the proposed
spacecraft.","Michael fogel, Snigdha Sushil Mishra, Laurent Burlion",2024-12-30,http://arxiv.org/abs/2412.20659v1,eess.SY,"The SPICEsat mission aims to study fluid sloshing in spacecraft using a cubesat platform, examining zero-g propellant sloshing and developing novel detection and computer vision methods to improve simulations and spacecraft maneuverability.","Nanosatellite, Propellant Sloshing, Design",
Energy Efficient LoRaWAN in LEO Satellites,"LPWAN service's inexpensive cost and long range capabilities make it a
promising addition and countless satellite companies have started taking
advantage of this technology to connect IoT users across the globe. However,
LEO satellites have the unique challenge of using rechargeable batteries and
green solar energy to power their components. LPWAN technology is not optimized
to maximize battery lifespan of network nodes. By incorporating a MAC protocol
that maximizes node the battery lifespan across the network, we can reduce
battery waste and usage of scarce Earth resources to develop satellite
batteries.","Muskan Shergill, Zach Thompson, Guanqun Song, Ting Zhu",2024-12-30,http://arxiv.org/abs/2412.20660v1,cs.ET,"LPWAN technology can be optimized to maximize the battery lifespan of network nodes, reducing battery waste and increasing the efficiency of satellite battery usage.",LoRaWAN Satellite Energy Efficient,
"Enhancing Table Recognition with Vision LLMs: A Benchmark and
  Neighbor-Guided Toolchain Reasoner","Pre-trained foundation models have recently significantly progressed in
structured table understanding and reasoning. However, despite advancements in
areas such as table semantic understanding and table question answering,
recognizing the structure and content of unstructured tables using Vision Large
Language Models (VLLMs) remains under-explored. In this work, we address this
research gap by employing VLLMs in a training-free reasoning paradigm. First,
we design a benchmark with various hierarchical dimensions relevant to table
recognition. Subsequently, we conduct in-depth evaluations using pre-trained
VLLMs, finding that low-quality image input is a significant bottleneck in the
recognition process. Drawing inspiration from these findings, we propose the
Neighbor-Guided Toolchain Reasoner (NGTR) framework, which is characterized by
integrating multiple lightweight models for low-level visual processing
operations aimed at mitigating issues with low-quality input images.
Specifically, we utilize a neighbor retrieval mechanism to guide the generation
of multiple tool invocation plans, transferring tool selection experiences from
similar neighbors to the given input, thereby facilitating suitable tool
selection. Additionally, we introduce a reflection module to supervise the tool
invocation process. Extensive experiments on public table recognition datasets
demonstrate that our approach significantly enhances the recognition
capabilities of the vanilla VLLMs. We believe that the designed benchmark and
the proposed NGTR framework could provide an alternative solution in table
recognition.","Yitong Zhou, Mingyue Cheng, Qingyang Mao, Qi Liu, Feiyang Xu, Xin Li, Enhong Chen",2024-12-30,http://arxiv.org/abs/2412.20662v1,cs.CV,"The paper addresses the understudied task of recognizing the structure and content of unstructured tables using pre-trained Vision Large Language Models (VLLMs) in a training-free reasoning paradigm, proposing the Neighbor-Guided Toolchain Reasoner (NGTR) framework to mitigate issues with low-quality input images.","Table recognition, Vision LLMs, Benchmark",
SM3Det: A Unified Model for Multi-Modal Remote Sensing Object Detection,"With the rapid advancement of remote sensing technology, high-resolution
multi-modal imagery is now more widely accessible. Conventional Object
detection models are trained on a single dataset, often restricted to a
specific imaging modality and annotation format. However, such an approach
overlooks the valuable shared knowledge across multi-modalities and limits the
model's applicability in more versatile scenarios. This paper introduces a new
task called Multi-Modal Datasets and Multi-Task Object Detection (M2Det) for
remote sensing, designed to accurately detect horizontal or oriented objects
from any sensor modality. This task poses challenges due to 1) the trade-offs
involved in managing multi-modal modelling and 2) the complexities of
multi-task optimization. To address these, we establish a benchmark dataset and
propose a unified model, SM3Det (Single Model for Multi-Modal datasets and
Multi-Task object Detection). SM3Det leverages a grid-level sparse MoE backbone
to enable joint knowledge learning while preserving distinct feature
representations for different modalities. Furthermore, it integrates a
consistency and synchronization optimization strategy using dynamic learning
rate adjustment, allowing it to effectively handle varying levels of learning
difficulty across modalities and tasks. Extensive experiments demonstrate
SM3Det's effectiveness and generalizability, consistently outperforming
specialized models on individual datasets. The code is available at
https://github.com/zcablii/SM3Det.","Yuxuan Li, Xiang Li, Yunheng Li, Yicheng Zhang, Yimian Dai, Qibin Hou, Ming-Ming Cheng, Jian Yang",2024-12-30,http://arxiv.org/abs/2412.20665v1,cs.CV,"This paper introduces the Multi-Modal Datasets and Multi-Task Object Detection (M2Det) task for remote sensing, which aims to accurately detect objects across various sensor modalities, and proposes a unified model, SM3Det, that leverages a grid-level sparse MoE backbone and a consistency and synchronization optimization strategy.",Multi-Modal Remote,
Recurrence-based Vanishing Point Detection,"Classical approaches to Vanishing Point Detection (VPD) rely solely on the
presence of explicit straight lines in images, while recent supervised deep
learning approaches need labeled datasets for training. We propose an
alternative unsupervised approach: Recurrence-based Vanishing Point Detection
(R-VPD) that uses implicit lines discovered from recurring correspondences in
addition to explicit lines. Furthermore, we contribute two
Recurring-Pattern-for-Vanishing-Point (RPVP) datasets: 1) a Synthetic Image
dataset with 3,200 ground truth vanishing points and camera parameters, and 2)
a Real-World Image dataset with 1,400 human annotated vanishing points. We
compare our method with two classical methods and two state-of-the-art deep
learning-based VPD methods. We demonstrate that our unsupervised approach
outperforms all the methods on the synthetic images dataset, outperforms the
classical methods, and is on par with the supervised learning approaches on
real-world images.","Skanda Bharadwaj, Robert Collins, Yanxi Liu",2024-12-30,http://arxiv.org/abs/2412.20666v1,cs.CV,"An unsupervised vanishing point detection method called Recurrence-based Vanishing Point Detection (R-VPD) is proposed, which uses implicit lines discovered from recurring correspondences in addition to explicit lines, outperforming classical and deep learning-based methods on synthetic and real-world image datasets.",Recurrence Vanishing Point,
"Highway Managed Lane Usage and Tolling for Mixed Traffic Flows with
  Connected Automated Vehicles (CAVs) and High-Occupancy Vehicles (HOVs)","This paper investigates managed lane (ML) toll setting and its effect under
mixed traffic of connected automated vehicles (CAVs), high-occupancy vehicles
(HOVs), and human-driven vehicles (HDVs), with a goal to avoid flow breakdown
and minimize total social cost. A mesoscopic finite-difference traffic
simulation model considers the flow-density relationship at different CAV
market penetration rates, lane-changing behavior, and multiple entries/exits,
interacting with a reactive toll setting mechanism. The results of the Monte
Carlo simulation suggest an optimal policy of untolled HOV/CAV use with HDV
tolls in particular scenarios of limited CAV market penetration. Small and
targeted tolling avoids flow breakdown in ML while prioritizing HOVs and other
vehicles with high values of time. Extensions of the formulation and
sensitivity analysis quantify the benefits of converting high-occupancy HDVs to
CAVs. The optimal tolling regime combines traffic science notions of flow
stability and the economics of resource allocation.","Max T. M. Ng, Hani S. Mahmassani",2024-12-30,http://arxiv.org/abs/2412.20667v1,eess.SY,"This study investigates the optimal toll settings for managed lanes with mixed traffic, including connected automated vehicles, high-occupancy vehicles, and human-driven vehicles, to avoid flow breakdown and minimize total social cost.",Managed Lanes Tolling CAVs,
"Prototypical Distillation and Debiased Tuning for Black-box Unsupervised
  Domain Adaptation","Unsupervised domain adaptation aims to transfer knowledge from a related,
label-rich source domain to an unlabeled target domain, thereby circumventing
the high costs associated with manual annotation. Recently, there has been
growing interest in source-free domain adaptation, a paradigm in which only a
pre-trained model, rather than the labeled source data, is provided to the
target domain. Given the potential risk of source data leakage via model
inversion attacks, this paper introduces a novel setting called black-box
domain adaptation, where the source model is accessible only through an API
that provides the predicted label along with the corresponding confidence value
for each query. We develop a two-step framework named $\textbf{Pro}$totypical
$\textbf{D}$istillation and $\textbf{D}$ebiased tun$\textbf{ing}$
($\textbf{ProDDing}$). In the first step, ProDDing leverages both the raw
predictions from the source model and prototypes derived from the target domain
as teachers to distill a customized target model. In the second step, ProDDing
keeps fine-tuning the distilled model by penalizing logits that are biased
toward certain classes. Empirical results across multiple benchmarks
demonstrate that ProDDing outperforms existing black-box domain adaptation
methods. Moreover, in the case of hard-label black-box domain adaptation, where
only predicted labels are available, ProDDing achieves significant improvements
over these methods. Code will be available at
\url{https://github.com/tim-learn/ProDDing/}.","Jian Liang, Lijun Sheng, Hongmin Liu, Ran He",2024-12-30,http://arxiv.org/abs/2412.20670v1,cs.LG,"The proposed method, ProDDing, is a two-step framework for black-box domain adaptation that leverages prototype-based distillation and debiased tuning to transfer knowledge from a pre-trained source model to an unlabeled target domain.",Prototypical Distillation Debiased Tuning,
"Two Birds with One Stone: Improving Rumor Detection by Addressing the
  Unfairness Issue","The degraded performance and group unfairness caused by confounding sensitive
attributes in rumor detection remains relatively unexplored. To address this,
we propose a two-step framework. Initially, it identifies confounding sensitive
attributes that limit rumor detection performance and cause unfairness across
groups. Subsequently, we aim to learn equally informative representations
through invariant learning. Our method considers diverse sets of groups without
sensitive attribute annotations. Experiments show our method easily integrates
with existing rumor detectors, significantly improving both their detection
performance and fairness.","Junyi Chen, Mengjia Wu, Qian Liu, Ying Ding, Yi Zhang",2024-12-30,http://arxiv.org/abs/2412.20671v1,cs.SI,"A two-step framework is proposed to identify sensitive attributes in rumor detection, addressing performance degradation and group unfairness, and learn equally informative representations through invariant learning to improve detection performance and fairness.","Rumor Detection, Fairness, Unfairness",
"Blockchain-Empowered Cyber-Secure Federated Learning for Trustworthy
  Edge Computing","Federated Learning (FL) is a privacy-preserving distributed machine learning
scheme, where each participant data remains on the participating devices and
only the local model generated utilizing the local computational power is
transmitted throughout the database. However, the distributed computational
nature of FL creates the necessity to develop a mechanism that can remotely
trigger any network agents, track their activities, and prevent threats to the
overall process posed by malicious participants. Particularly, the FL paradigm
may become vulnerable due to an active attack from the network participants,
called a poisonous attack. In such an attack, the malicious participant acts as
a benign agent capable of affecting the global model quality by uploading an
obfuscated poisoned local model update to the server. This paper presents a
cross-device FL model that ensures trustworthiness, fairness, and authenticity
in the underlying FL training process. We leverage trustworthiness by
constructing a reputation-based trust model based on contributions of agents
toward model convergence. We ensure fairness by identifying and removing
malicious agents from the training process through an outlier detection
technique. Further, we establish authenticity by generating a token for each
participating device through a distributed sensing mechanism and storing that
unique token in a blockchain smart contract. Further, we insert the trust
scores of all agents into a blockchain and validate their reputations using
various consensus mechanisms that consider the computational task.","Ervin Moore, Ahmed Imteaj, Md Zarif Hossain, Shabnam Rezapour, M. Hadi Amini",2024-12-30,http://arxiv.org/abs/2412.20674v1,cs.DC,"This paper proposes a Trustworthiness, Fairness, and Authenticity (TFA) mechanism for Federated Learning (FL) to prevent poisonous attacks and ensure reliable model convergence, fairness, and authenticity by using a reputation-based trust model and blockchain-based authentication.",Blockchain Cyber-Secure Federated,
"Improved ICNN-LSTM Model Classification Based on Attitude Sensor Data
  for Hazardous State Assessment of Magnetic Adhesion Climbing Wall Robots","Magnetic adhesion tracked climbing robots are widely utilized in
high-altitude inspection, welding, and cleaning tasks due to their ability to
perform various operations against gravity on vertical or inclined walls.
However, during operation, the robot may experience overturning torque caused
by its own weight and load, which can lead to the detachment of magnetic plates
and subsequently pose safety risks. This paper proposes an improved ICNN-LSTM
network classification method based on Micro-Electro-Mechanical Systems (MEMS)
attitude sensor data for real-time monitoring and assessment of hazardous
states in magnetic adhesion tracked climbing robots. Firstly, a data
acquisition strategy for attitude sensors capable of capturing minute
vibrations is designed. Secondly, a feature extraction and classification model
combining an Improved Convolutional Neural Network (ICNN) with a Long
Short-Term Memory (LSTM) network is proposed. Experimental validation
demonstrates that the proposed minute vibration sensing method achieves
significant results, and the proposed classification model consistently
exhibits high accuracy compared to other models. The research findings provide
effective technical support for the safe operation of climbing robots","Zhen Ma, He Xu, Jielong Dou, Yi Qin, Xueyu Zhang",2024-12-30,http://arxiv.org/abs/2412.20675v1,cs.RO,This paper proposes a classification method using an ICNN-LSTM network to monitor and assess hazardous states in magnetic adhesion tracked climbing robots through real-time analysis of MEMS attitude sensor data.,"ICNN, LSTM, Attitude",
"Align Attention Heads Before Merging Them: An Effective Way for
  Converting MHA to GQA","Large language models have been shown to perform well on a variety of natural
language processing problems. However, as the model size and the input
sequence's length increase, the rapid increase of KV Cache significantly slows
down inference speed. Therefore GQA model, as an alternative to MHA model, has
been widely introduced into LLMs. In this work, we propose a low-cost method
for pruning MHA models into GQA models with any compression ratio of key-value
heads. Our method is based on $\mathit{L_0}$ masks to gradually remove
redundant parameters. In addition, we apply orthogonal transformations to
attention heads without changing the model to increase similarity between
attention heads before pruning training, in order to further improve
performance of the model. Our method can be compatible with rotary position
embedding (RoPE), which means the model after training can be fully adapted to
the mainstream standard GQA framework. Experiments demonstrate that our
strategy can compress up to 87.5% of key-value heads of the LLaMA2-7B model
without too much performance degradation, just achieved through supervised
fine-tuning.","Qingyun Jin, Xiaohui Song, Feng Zhou, Zengchang Qin",2024-12-30,http://arxiv.org/abs/2412.20677v1,cs.CL,A low-cost method is proposed for pruning MHA models into GQA models with any compression ratio of key-value heads using L0 masks and orthogonal transformations to improve performance.,MHA,
Attention-Driven Metapath Encoding in Heterogeneous Graphs,"One of the emerging techniques in node classification in heterogeneous graphs
is to restrict message aggregation to pre-defined, semantically meaningful
structures called metapaths. This work is the first attempt to incorporate
attention into the process of encoding entire metapaths without dropping
intermediate nodes. In particular, we construct two encoders: the first uses
sequential attention to extend the multi-hop message passing algorithm designed
in \citet{magna} to the metapath setting, and the second incorporates direct
attention to extract semantic relations in the metapath. The model then employs
the intra-metapath and inter-metapath aggregation mechanisms of \citet{han}. We
furthermore use the powerful training scheduler specialized for heterogeneous
graphs that was developed in \citet{lts}, ensuring the model slowly learns how
to classify the most difficult nodes. The result is a resilient,
general-purpose framework for capturing semantic structures in heterogeneous
graphs. In particular, we demonstrate that our model is competitive with
state-of-the-art models on performing node classification on the IMDB dataset,
a popular benchmark introduced in \citet{benchmark}.",Calder Katyal,2024-12-30,http://arxiv.org/abs/2412.20678v1,cs.LG,"The paper proposes a framework for node classification in heterogeneous graphs using metapaths, incorporating attention mechanisms to encode entire metapaths without dropping intermediate nodes.",Attention-Driven Metapath Encoding Heterogeneous Graphs,
"Differentiable Convex Optimization Layers in Neural Architectures:
  Foundations and Perspectives","The integration of optimization problems within neural network architectures
represents a fundamental shift from traditional approaches to handling
constraints in deep learning. While it is long known that neural networks can
incorporate soft constraints with techniques such as regularization, strict
adherence to hard constraints is generally more difficult. A recent advance in
this field, however, has addressed this problem by enabling the direct
embedding of optimization layers as differentiable components within deep
networks. This paper surveys the evolution and current state of this approach,
from early implementations limited to quadratic programming, to more recent
frameworks supporting general convex optimization problems. We provide a
comprehensive review of the background, theoretical foundations, and emerging
applications of this technology. Our analysis includes detailed mathematical
proofs and an examination of various use cases that demonstrate the potential
of this hybrid approach. This work synthesizes developments at the intersection
of optimization theory and deep learning, offering insights into both current
capabilities and future research directions in this rapidly evolving field.",Calder Katyal,2024-12-30,http://arxiv.org/abs/2412.20679v1,cs.LG,"This paper surveys the integration of optimization problems within neural network architectures, enabling the direct embedding of optimization layers as differentiable components within deep networks, with a focus on the evolution, current state, and emerging applications of this technology.","Convex Optimization, Neural Architectures",
"Online Adaptive Platoon Control for Connected and Automated Vehicles via
  Physics Enhanced Residual Learning","This paper introduces a physics enhanced residual learning (PERL) framework
for connected and automated vehicle (CAV) platoon control, addressing the
dynamics and unpredictability inherent to platoon systems. The framework first
develops a physics-based controller to model vehicle dynamics, using driving
speed as input to optimize safety and efficiency. Then the residual controller,
based on neural network (NN) learning, enriches the prior knowledge of the
physical model and corrects residuals caused by vehicle dynamics. By
integrating the physical model with data-driven online learning, the PERL
framework retains the interpretability and transparency of physics-based models
and enhances the adaptability and precision of data-driven learning, achieving
significant improvements in computational efficiency and control accuracy in
dynamic scenarios. Simulation and robot car platform tests demonstrate that
PERL significantly outperforms pure physical and learning models, reducing
average cumulative absolute position and speed errors by up to 58.5% and 40.1%
(physical model) and 58.4% and 47.7% (NN model). The reduced-scale robot car
platform tests further validate the adaptive PERL framework's superior accuracy
and rapid convergence under dynamic disturbances, reducing position and speed
cumulative errors by 72.73% and 99.05% (physical model) and 64.71% and 72.58%
(NN model). PERL enhances platoon control performance through online parameter
updates when external disturbances are detected. Results demonstrate the
advanced framework's exceptional accuracy and rapid convergence capabilities,
proving its effectiveness in maintaining platoon stability under diverse
conditions.","Peng Zhang, Heye Huang, Hang Zhou, Haotian Shi, Keke Long, Xiaopeng Li",2024-12-30,http://arxiv.org/abs/2412.20680v1,cs.RO,"The paper introduces a physics-enhanced residual learning (PERL) framework for connected and automated vehicle (CAV) platoon control, which combines physical modeling with neural network learning to achieve significant improvements in computational efficiency and control accuracy in dynamic scenarios.","Connected Vehicles, Adaptive Control, Residual Learning",
Learning to Rank Pre-trained Vision-Language Models for Downstream Tasks,"Vision language models (VLMs) like CLIP show stellar zero-shot capability on
classification benchmarks. However, selecting the VLM with the highest
performance on the unlabeled downstream task is non-trivial. Existing VLM
selection methods focus on the class-name-only setting, relying on a supervised
large-scale dataset and large language models, which may not be accessible or
feasible during deployment. This paper introduces the problem of
\textbf{unsupervised vision-language model selection}, where only unsupervised
downstream datasets are available, with no additional information provided. To
solve this problem, we propose a method termed Visual-tExtual Graph Alignment
(VEGA), to select VLMs without any annotations by measuring the alignment of
the VLM between the two modalities on the downstream task. VEGA is motivated by
the pretraining paradigm of VLMs, which aligns features with the same semantics
from the visual and textual modalities, thereby mapping both modalities into a
shared representation space. Specifically, we first construct two graphs on the
vision and textual features, respectively. VEGA is then defined as the overall
similarity between the visual and textual graphs at both node and edge levels.
Extensive experiments across three different benchmarks, covering a variety of
application scenarios and downstream datasets, demonstrate that VEGA
consistently provides reliable and accurate estimates of VLMs' performance on
unlabeled downstream tasks.","Yuhe Ding, Bo Jiang, Aihua Zheng, Qin Xu, Jian Liang",2024-12-30,http://arxiv.org/abs/2412.20682v1,cs.CV,"The paper introduces Visual-tExtual Graph Alignment (VEGA), a method for selecting vision language models without annotations by measuring the alignment between visual and textual modalities on the downstream task.",Pre-trained Vision-Language Models Ranking Downstream,
"MarsSQE: Stereo Quality Enhancement for Martian Images Using Bi-level
  Cross-view Attention","Stereo images captured by Mars rovers are transmitted after lossy compression
due to the limited bandwidth between Mars and Earth. Unfortunately, this
process results in undesirable compression artifacts. In this paper, we present
a novel stereo quality enhancement approach for Martian images, named MarsSQE.
First, we establish the first dataset of stereo Martian images. Through
extensive analysis of this dataset, we observe that cross-view correlations in
Martian images are notably high. Leveraging this insight, we design a bi-level
cross-view attention-based quality enhancement network that fully exploits
these inherent cross-view correlations. Specifically, our network integrates
pixel-level attention for precise matching and patch-level attention for
broader contextual information. Experimental results demonstrate the
effectiveness of our MarsSQE approach.","Mai Xu, Yinglin Zhu, Qunliang Xing, Jing Yang, Xin Zou",2024-12-30,http://arxiv.org/abs/2412.20685v1,eess.IV,"A novel approach, MarsSQE, is presented for enhancing the quality of stereo images captured by Mars rovers and transmitted after lossy compression, leveraging high cross-view correlations between Martian images.","MarsSQE, Bi-level, Attention",
Powering the Future: Innovations in Electric Vehicle Battery Recycling,"The global shift towards electric vehicles (EVs) as a sustainable alternative
to traditional gasoline-powered cars has triggered a significant rise in the
demand for lithium-ion batteries. However, as the adoption of EVs grows, the
issue of battery disposal and recycling has emerged as a critical challenge.
The recycling of EV batteries is essential not only for reducing the
environmental impact of battery waste but also for ensuring the sustainable
supply of critical raw materials such as lithium, cobalt, and nickel. This
paper explores recent innovations in the field of electric vehicle battery
recycling, examining advanced techniques such as direct recycling,
hydrometallurgical processes, and sustainable battery design. It also
highlights the role of policy and industry collaboration in improving recycling
infrastructure and addressing the economic and environmental challenges
associated with battery waste. By focusing on both the technical and regulatory
aspects of EV battery recycling, this paper aims to provide a comprehensive
overview of the state of the industry and the future outlook for recycling
technologies, ultimately paving the way for a cleaner, more sustainable future
in transportation.","Venkata Sai Chandra Prasanth Narisetty, Tejaswi Maddineni",2024-12-30,http://arxiv.org/abs/2412.20687v1,cs.CE,"The paper explores innovations in electric vehicle battery recycling, including new techniques and sustainable design, and highlights the importance of policy and industry collaboration to address the environmental and economic challenges of battery waste disposal.",electric vehicle battery recycling innovations power,
"Revolutionizing Mobility:The Latest Advancements in Autonomous Vehicle
  Technology","Autonomous vehicle (AV) technology is transforming the landscape of
transportation bypromising safer, more efficient, and sustainable
mobilitysolutions. In recent years, significant advancements in AI, machine
learning, sensor fusion, and
vehicle-to-everything(V2X)communicationhavepropelledthedevelopmentoffullyautonomous
vehicles. This paper explores the cutting-edge technologies driving the
evolution of
AVs,thechallengesfacedintheirdeployment,andthepotentialsocietal,economic,and
regulatory impacts. It highlights the key innovations in perception systems,
decision-making algorithms, and infrastructure integration, as well as the
emerging trends towards Level 4 and Level 5 autonomy. The paper also discusses
future directions, including ethical considerations and the roadmap to mass
adoption of autonomous mobility. Ultimately, the
integrationofautonomousvehicles into globaltransportation systems is expected
to revolutionize urban planning, reduce traffic accidents, and
significantlyloweremissions,pavingthewayforasmarterandmoresustainablefuture.","Venkata Sai Chandra Prasanth Narisetty, Tejaswi Maddineni",2024-12-30,http://arxiv.org/abs/2412.20688v1,cs.CE,"Autonomous vehicle technology is evolving rapidly due to advancements in AI, machine learning, and sensor fusion, promising safer, more efficient, and sustainable mobility solutions.",Autonomous Vehicle Technology,
"Modeling and Simulating Agent-Based City Migration Using Conway's Game
  of Life","Agent-based modeling (ABM) has become a cornerstone of complexity science,
enabling the study of heterogeneous agents interacting within dynamic
environments. Among ABM frameworks, John Conway's Game of Life (GoL) stands out
for its simplicity and ability to generate emergent macroscopic patterns from
basic microscopic rules. In this paper, we propose and implement a novel
GoL-based framework to simulate urban migration dynamics. Using a
grid-within-a-grid approach, our approach encodes probabilistic tendencies for
out-migration due to densification and sparsification, simulating the evolution
of population centers. By initializing GoL grids with different distributions
and parameterizing migration preferences, we explore how urban structures
emerge and stabilize over time. Through a series of experiments, we demonstrate
that even with simple rules, this framework shows promise for understanding
emergent urban phenomena, providing insights into city growth and structure.
Methodologically, our framework offers a versatile and computationally
efficient tool for studying urban migration patterns, contributing to the
broader application of ABMs in computational urban social science.","Bruce Deng, Mayank Kejriwal",2024-12-30,http://arxiv.org/abs/2412.20691v1,cs.CY,"This paper proposes a novel agent-based modeling framework, based on John Conway's Game of Life, to simulate urban migration dynamics and study the emergence of urban structures over time.",agent-based migration Conway's Game,
"Test Adequacy for Metamorphic Testing: Criteria, Measurement, and
  Implication","Metamorphic testing (MT) is a simple yet effective technique to alleviate the
oracle problem in software testing. The underlying idea of MT is to test a
software system by checking whether metamorphic relations (MRs) hold among
multiple test inputs (including source and follow-up inputs) and the actual
output of their executions. Since MRs and source inputs are two essential
components of MT, considerable efforts have been made to examine the systematic
identification of MRs and the effective generation of source inputs, which has
greatly enriched the fundamental theory of MT since its invention. However, few
studies have investigated the test adequacy assessment issue of MT, which
hinders the objective measurement of MT's test quality as well as the effective
construction of test suites. Although in the context of traditional software
testing, there exist a number of test adequacy criteria that specify testing
requirements to constitute an adequate test from various perspectives, they are
not in line with MT's focus which is to test the software under testing (SUT)
from the perspective of necessary properties. In this paper, we proposed a new
set of criteria that specifies testing requirements from the perspective of
necessary properties satisfied by the SUT, and designed a test adequacy
measurement that evaluates the degree of adequacy based on both MRs and source
inputs. The experimental results have shown that the proposed measurement can
effectively indicate the fault detection effectiveness of test suites, i.e.,
test suites with increased test adequacy usually exhibit higher effectiveness
in fault detection. Our work made an attempt to assess the test adequacy of MT
from a new perspective, and our criteria and measurement provide a new approach
to evaluate the test quality of MT and provide guidelines for constructing
effective test suites of MT.","An Fu, Chang-ai Sun, Jiaming Zhang, Huai Liu",2024-12-30,http://arxiv.org/abs/2412.20692v1,cs.SE,"This paper proposes a new set of criteria and measurement for test adequacy assessment in metamorphic testing, which evaluates the degree of adequacy based on metamorphic relations and source inputs, and showed that it can effectively indicate the fault detection effectiveness of test suites.",Test adequacy metamorphic testing criteria measurement implication,
"UBER: Uncertainty-Based Evolution with Large Language Models for
  Automatic Heuristic Design","NP-hard problem-solving traditionally relies on heuristics, but manually
crafting effective heuristics for complex problems remains challenging. While
recent work like FunSearch has demonstrated that large language models (LLMs)
can be leveraged for heuristic design in evolutionary algorithm (EA)
frameworks, their potential is not fully realized due to its deficiency in
exploitation and exploration. We present UBER (Uncertainty-Based Evolution for
Refinement), a method that enhances LLM+EA methods for automatic heuristic
design by integrating uncertainty on top of the FunSearch framework. UBER
introduces two key innovations: an Uncertainty-Inclusive Evolution Process
(UIEP) for adaptive exploration-exploitation balance, and a principled
Uncertainty-Inclusive Island Reset (UIIS) strategy for maintaining population
diversity. Through extensive experiments on challenging NP-complete problems,
UBER demonstrates significant improvements over FunSearch. Our work provides a
new direction for the synergy of LLMs and EA, advancing the field of automatic
heuristic design.","Zijie Chen, Zhanchao Zhou, Yu Lu, Renjun Xu, Lili Pan, Zhenzhong Lan",2024-12-30,http://arxiv.org/abs/2412.20694v1,cs.NE,"This abstract presents UBER, a method that enhances the automatic heuristic design technique FunSearch by incorporating uncertainty into the evolutionary algorithm framework to improve exploration-exploitation balance and population diversity.","Evolution, Uncertainty, Heuristic",
"CoCap: Coordinated motion Capture for multi-actor scenes in outdoor
  environments","Motion capture has become increasingly important, not only in computer
animation but also in emerging fields like the virtual reality, bioinformatics,
and humanoid training. Capturing outdoor environments offers extended horizon
scenes but introduces challenges with occlusions and obstacles. Recent
approaches using multi-drone systems to capture multiple actor scenes often
fail to account for multi-view consistency and reasoning across cameras in
cluttered environments. Coordinated motion Capture (CoCap), inspired by
Conflict-Based Search (CBS), addresses this issue by coordinating view planning
to ensure multi-view reasoning during conflicts. In scenarios with high
occlusions and obstacles, where the likelihood of inter-robot collisions
increases, CoCap demonstrates performance that approaches the ideal outcomes of
unconstrained planning, outperforming existing sequential planning methods.
Additionally, CoCap offers a single-robot view search approach for real-time
applications in dense environments.","Aditya Rauniyar, Micah Corah, Sebastian Scherer",2024-12-30,http://arxiv.org/abs/2412.20695v1,cs.RO,"Coordinated motion Capture (CoCap) uses Conflict-Based Search (CBS) to coordinate view planning, ensuring multi-view reasoning in cluttered environments with high occlusions and obstacles, outperforming existing sequential planning methods.","Motion Capture, Coordinated, Outdoor Environments",
"An inverse obstacle scattering problem with random sources in the time
  domain","This work considers a time domain inverse acoustic obstacle scattering
problem due to randomly distributed point sources. Motivated by the
Helmholtz-Kirchhoff identity in the frequency domain, we propose to relate the
time domain measurement data due to random sources to an approximate data set
given by the subtraction of two scattered wave fields. We propose a time domain
linear sampling method for the approximate data set and show how to tackle the
measurement data due to random sources. An imaging functional is built based on
the linear sampling method, which reconstructs the support of the unknown
scattering object using directly the time domain measurements. The functional
framework is based on the Laplace transform, which relates the mapping
properties of Laplace domain factorized operators to their counterparts in the
time domain. Numerical examples are provided to illustrate the capability of
the proposed method.","Xiaoli Liu, Shixu Meng, Jialu Tian, Bo Zhang",2024-12-30,http://arxiv.org/abs/2412.20697v1,math.NA,This paper proposes a time domain linear sampling method for reconstructing the support of an unknown scattering object using direct measurements from randomly distributed point sources.,"inverse scattering, random sources, time domain",
"Air-Ground Collaborative Robots for Fire and Rescue Missions: Towards
  Mapping and Navigation Perspective","Air-ground collaborative robots have shown great potential in the field of
fire and rescue, which can quickly respond to rescue needs and improve the
efficiency of task execution. Mapping and navigation, as the key foundation for
air-ground collaborative robots to achieve efficient task execution, have
attracted a great deal of attention. This growing interest in collaborative
robot mapping and navigation is conducive to improving the intelligence of fire
and rescue task execution, but there has been no comprehensive investigation of
this field to highlight their strengths. In this paper, we present a systematic
review of the ground-to-ground cooperative robots for fire and rescue from a
new perspective of mapping and navigation. First, an air-ground collaborative
robots framework for fire and rescue missions based on unmanned aerial vehicle
(UAV) mapping and unmanned ground vehicle (UGV) navigation is introduced. Then,
the research progress of mapping and navigation under this framework is
systematically summarized, including UAV mapping, UAV/UGV co-localization, and
UGV navigation, with their main achievements and limitations. Based on the
needs of fire and rescue missions, the collaborative robots with different
numbers of UAVs and UGVs are classified, and their practicality in fire and
rescue tasks is elaborated, with a focus on the discussion of their merits and
demerits. In addition, the application examples of air-ground collaborative
robots in various firefighting and rescue scenarios are given. Finally, this
paper emphasizes the current challenges and potential research opportunities,
rounding up references for practitioners and researchers willing to engage in
this vibrant area of air-ground collaborative robots.","Ying Zhang, Haibao Yan, Danni Zhu, Jiankun Wang, Cui-Hua Zhang, Weili Ding, Xi Luo, Changchun Hua, Max Q. -H. Meng",2024-12-30,http://arxiv.org/abs/2412.20699v1,cs.RO,"This paper presents a systematic review of the development of air-ground collaborative robots for fire and rescue missions, focusing on mapping and navigation, and highlights their strengths and limitations.","Collaborative Robots, Fire Rescue",
Optimal rolling of fair dice using fair coins,"In 1976, Knuth and Yao presented an algorithm for sampling from a finite
distribution using flips of a fair coin that on average used the optimal number
of flips. Here we show how to easily run their algorithm for the special case
of rolling a fair die that uses memory linear in the input. Analysis of this
algorithm yields a bound on the average number of coin flips needed that is
slightly better than the original Knuth-Yao bound. This can then be extended to
discrete distributions in a near optimal number of flips again using memory
linear in the input.","Mark Huber, Danny Vargas",2024-12-30,http://arxiv.org/abs/2412.20700v1,cs.DS,"The abstract discusses a modification of the Knuth-Yao algorithm for sampling from a finite distribution using coin flips, which achieves a better-than-optimal average number of flips for rolling a fair die or sampling from discrete distributions.",dice rolling,
Open-Set Object Detection By Aligning Known Class Representations,"Open-Set Object Detection (OSOD) has emerged as a contemporary research
direction to address the detection of unknown objects. Recently, few works have
achieved remarkable performance in the OSOD task by employing contrastive
clustering to separate unknown classes. In contrast, we propose a new semantic
clustering-based approach to facilitate a meaningful alignment of clusters in
semantic space and introduce a class decorrelation module to enhance
inter-cluster separation. Our approach further incorporates an object focus
module to predict objectness scores, which enhances the detection of unknown
objects. Further, we employ i) an evaluation technique that penalizes
low-confidence outputs to mitigate the risk of misclassification of the unknown
objects and ii) a new metric called HMP that combines known and unknown
precision using harmonic mean. Our extensive experiments demonstrate that the
proposed model achieves significant improvement on the MS-COCO & PASCAL VOC
dataset for the OSOD task.","Hiran Sarkar, Vishal Chudasama, Naoyuki Onoe, Pankaj Wasnik, Vineeth N Balasubramanian",2024-12-30,http://arxiv.org/abs/2412.20701v1,cs.CV,"A new semantic clustering-based approach is proposed for Open-Set Object Detection, incorporating a class decorrelation module, object focus module, and evaluation technique to detect unknown objects with improved performance on MS-COCO and PASCAL VOC datasets.",Open-set Known Class,
"The Restricted Inverse Optimal Value Problem under Weighted Bottle-neck
  Hamming distance on trees","We consider the Restricted Inverse Optimal Value Problem (RIOVSP) on trees
under weighted bottleneck Hamming distance, denoted as (RIOVSPT$_{BH}$). The
problem aims to minimize the total cost under weighted bottle-neck Hamming
distance such that the length of the shortest root-leaf path of the tree is
lower-bounded by a given value by adjusting the length of some edges.
Additionally, the specified lower bound must correspond to the length of a
particular root-leaf path. Through careful analysis of the problem's structural
properties, we develop an algorithm with $O(n\log n)$ time complexity to solve
(RIOVSPT$_{BH}$). Furthermore, by removing the path-length constraint, we
derive the Minimum Cost Shortest Path Interdiction Problem on Trees (MCSPIT),
for which we present an $O(n\log n)$ time algorithm that operates under
weighted bottleneck Hamming distance. Extensive computational experiments
demonstrate the efficiency and effectiveness of both algorithms.","Qiao Zhang, Xiao Li, Xiucui Guan",2024-12-30,http://arxiv.org/abs/2412.20703v1,cs.DS,"The abstract considers the Restricted Inverse Optimal Value Problem on trees under weighted bottleneck Hamming distance, and develops an O(nlogn) time algorithm to solve it, along with a related problem, Minimum Cost Shortest Path Interdiction Problem on Trees.",Restricted Inverse Optimal Value Problem,
"HFI: A unified framework for training-free detection and implicit
  watermarking of latent diffusion model generated images","Dramatic advances in the quality of the latent diffusion models (LDMs) also
led to the malicious use of AI-generated images. While current AI-generated
image detection methods assume the availability of real/AI-generated images for
training, this is practically limited given the vast expressibility of LDMs.
This motivates the training-free detection setup where no related data are
available in advance. The existing LDM-generated image detection method assumes
that images generated by LDM are easier to reconstruct using an autoencoder
than real images. However, we observe that this reconstruction distance is
overfitted to background information, leading the current method to
underperform in detecting images with simple backgrounds. To address this, we
propose a novel method called HFI. Specifically, by viewing the autoencoder of
LDM as a downsampling-upsampling kernel, HFI measures the extent of aliasing, a
distortion of high-frequency information that appears in the reconstructed
image. HFI is training-free, efficient, and consistently outperforms other
training-free methods in detecting challenging images generated by various
generative models. We also show that HFI can successfully detect the images
generated from the specified LDM as a means of implicit watermarking. HFI
outperforms the best baseline method while achieving magnitudes of","Sungik Choi, Sungwoo Park, Jaehoon Lee, Seunghyun Kim, Stanley Jungkyu Choi, Moontae Lee",2024-12-30,http://arxiv.org/abs/2412.20704v1,cs.CV,"The paper proposes a novel, training-free method called HFI for detecting artificial images generated by latent diffusion models, which measures the extent of aliasing in the reconstructed image to improve detection performance.","HFI, watermarking, diffusion model",
"Metadata-Enhanced Speech Emotion Recognition: Augmented Residual
  Integration and Co-Attention in Two-Stage Fine-Tuning","Speech Emotion Recognition (SER) involves analyzing vocal expressions to
determine the emotional state of speakers, where the comprehensive and thorough
utilization of audio information is paramount. Therefore, we propose a novel
approach on self-supervised learning (SSL) models that employs all available
auxiliary information -- specifically metadata -- to enhance performance.
Through a two-stage fine-tuning method in multi-task learning, we introduce the
Augmented Residual Integration (ARI) module, which enhances transformer layers
in encoder of SSL models. The module efficiently preserves acoustic features
across all different levels, thereby significantly improving the performance of
metadata-related auxiliary tasks that require various levels of features.
Moreover, the Co-attention module is incorporated due to its complementary
nature with ARI, enabling the model to effectively utilize multidimensional
information and contextual relationships from metadata-related auxiliary tasks.
Under pre-trained base models and speaker-independent setup, our approach
consistently surpasses state-of-the-art (SOTA) models on multiple SSL encoders
for the IEMOCAP dataset.","Zixiang Wan, Ziyue Qiu, Yiyang Liu, Wei-Qiang Zhang",2024-12-30,http://arxiv.org/abs/2412.20707v1,eess.AS,"A novel self-supervised learning approach is proposed for Speech Emotion Recognition, which utilizes metadata to enhance performance and incorporates the Augmented Residual Integration and Co-attention modules to improve feature preservation and multidimensional information utilization.","Keywords: Speech Emotion, Residual Integration, Co-Attention",
"Residual Connection Networks in Medical Image Processing: Exploration of
  ResUnet++ Model Driven by Human Computer Interaction","Accurate identification and localisation of brain tumours from medical images
remain challenging due to tumour variability and structural complexity.
Convolutional Neural Networks (CNNs), particularly ResNet and Unet, have made
significant progress in medical image processing, offering robust capabilities
for image segmentation. However, limited research has explored their
integration with human-computer interaction (HCI) to enhance usability,
interpretability, and clinical applicability. This paper introduces ResUnet++,
an advanced hybrid model combining ResNet and Unet++, designed to improve
tumour detection and localisation while fostering seamless interaction between
clinicians and medical imaging systems. ResUnet++ integrates residual blocks in
both the downsampling and upsampling phases, ensuring critical image features
are preserved. By incorporating HCI principles, the model provides intuitive,
real-time feedback, enabling clinicians to visualise and interact with tumour
localisation results effectively. This fosters informed decision-making and
supports workflow efficiency in clinical settings. We evaluated ResUnet++ on
the LGG Segmentation Dataset, achieving a Jaccard Loss of 98.17%. The results
demonstrate its strong segmentation performance and potential for real-world
applications. By bridging advanced medical imaging techniques with HCI,
ResUnet++ offers a foundation for developing interactive diagnostic tools,
improving clinician trust, decision accuracy, and patient outcomes, and
advancing the integration of AI in healthcare workflows.","Peixin Dai, Jingsi Zhang, Zhitao Shu",2024-12-30,http://arxiv.org/abs/2412.20709v1,eess.IV,"This paper introduces ResUnet++, a hybrid model combining ResNet and Unet++ that improves brain tumour detection and localisation while providing seamless interaction between clinicians and medical imaging systems.",ResUnet Residual Connection Medical Image,
How to Balance the Load Online When Jobs and Machines Are Both Selfish?,"In this paper, we study the classic optimization problem of Related Machine
Online Load Balancing under the conditions of selfish machines and selfish
jobs. We have $m$ related machines with varying speeds and $n$ jobs arriving
online with different sizes. Our objective is to design an online truthful
algorithm that minimizes the makespan while ensuring that jobs and machines
report their true sizes and speeds.
  Previous studies in the online scenario have primarily focused on selfish
jobs, beginning with the work of Aspnes et al. (JACM 1997). An
$O(1)$-competitive online mechanism for selfish jobs was discovered by Feldman,
Fiat, and Roytman (EC 2017). For selfish machines, truthful mechanisms have
only been explored in offline settings, starting with Archer and Tardos (FOCS
2001). The best-known results are two PTAS mechanisms by Christodoulou and
Kov\'{a}cs (SICOMP 2013) and Epstein et al. (MOR 2016).
  We design an online mechanism that is truthful for both machines and jobs,
achieving a competitive ratio of $O(\log m)$. This is the first non-trivial
two-sided truthful mechanism for online load balancing and also the first
non-trivial machine-side truthful mechanism. Furthermore, we extend our
mechanism to the $\ell_q$ norm variant of load balancing, maintaining two-sided
truthfulness with a competitive ratio of
$\tilde{O}(m^{\frac{1}{q}(1-\frac{1}{q})})$.","Wenqian Wang, Chenyang Xu, Yuhao Zhang",2024-12-30,http://arxiv.org/abs/2412.20711v1,cs.DS,"The paper designs an online load balancing algorithm that is truthful for both machines and jobs, achieving a competitive ratio of O(log m), and is the first non-trivial two-sided truthful mechanism for online load balancing and the first non-trivial machine-side truthful mechanism.",Selfish Machines Load,
"Inverse medium problems, saddle point formulation","In this paper we discuss inverse medium problems. We develop the direct
sampling method based on probing indices using the saddle point formulation.
The medium is constructed by solutions of saddle point problems. The method
improves the probing functions for the direct sampling method and directly
images the medium. The method is very efficient and can be applied to a general
class of inverse medium problems.",Kazufumi Ito,2024-12-30,http://arxiv.org/abs/2412.20713v1,math.NA,"The paper develops a direct sampling method for inverse medium problems based on probing indices using the saddle point formulation, allowing for efficient imaging of the medium.",Inverse medium problems saddle point formulation,
"Effective and Efficient Intracortical Brain Signal Decoding with Spiking
  Neural Networks","A brain-computer interface (BCI) facilitates direct interaction between the
brain and external devices. To concurrently achieve high decoding accuracy and
low energy consumption in invasive BCIs, we propose a novel spiking neural
network (SNN) framework incorporating local synaptic stabilization (LSS) and
channel-wise attention (CA), termed LSS-CA-SNN. LSS optimizes neuronal membrane
potential dynamics, boosting classification performance, while CA refines
neuronal activation, effectively reducing energy consumption. Furthermore, we
introduce SpikeDrop, a data augmentation strategy designed to expand the
training dataset thus enhancing model generalizability. Experiments on invasive
spiking datasets recorded from two rhesus macaques demonstrated that LSS-CA-SNN
surpassed state-of-the-art artificial neural networks (ANNs) in both decoding
accuracy and energy efficiency, achieving 0.80-3.87% performance gains and
14.78-43.86 times energy saving. This study highlights the potential of
LSS-CA-SNN and SpikeDrop in advancing invasive BCI applications.","Haotian Fu, Peng Zhang, Song Yang, Herui Zhang, Ziwei Wang, Dongrui Wu",2024-12-30,http://arxiv.org/abs/2412.20714v1,cs.HC,"The proposed LSS-CA-SNN framework with SpikeDrop data augmentation achieves high decoding accuracy and low energy consumption in invasive brain-computer interfaces, outperforming state-of-the-art ANNs in experiments on invasive spiking datasets.",Spiking Neural Networks Intracortical Brain Signal Decoding,
ChartAdapter: Large Vision-Language Model for Chart Summarization,"Chart summarization, which focuses on extracting key information from charts
and interpreting it in natural language, is crucial for generating and
delivering insights through effective and accessible data analysis. Traditional
methods for chart understanding and summarization often rely on multi-stage
pipelines, which may produce suboptimal semantic alignment between visual and
textual information. In comparison, recently developed LLM-based methods are
more dependent on the capability of foundation images or languages, while
ignoring the characteristics of chart data and its relevant challenges. To
address these limitations, we propose ChartAdapter, a novel lightweight
transformer module designed to bridge the gap between charts and textual
summaries. ChartAdapter employs learnable query vectors to extract implicit
semantics from chart data and incorporates a cross-modal alignment projector to
enhance vision-to-language generative learning. By integrating ChartAdapter
with an LLM, we enable end-to-end training and efficient chart summarization.
To further enhance the training, we introduce a three-stage hierarchical
training procedure and develop a large-scale dataset specifically curated for
chart summarization, comprising 190,618 samples. Experimental results on the
standard Chart-to-Text testing set demonstrate that our approach significantly
outperforms existing methods, including state-of-the-art models, in generating
high-quality chart summaries. Ablation studies further validate the
effectiveness of key components in ChartAdapter. This work highlights the
potential of tailored LLM-based approaches to advance chart understanding and
sets a strong foundation for future research in this area.","Peixin Xu, Yujuan Ding, Wenqi Fan",2024-12-30,http://arxiv.org/abs/2412.20715v1,cs.MM,"The ChartAdapter is a novel transformer module that helps bridge the gap between charts and textual summaries by extracting implicit semantics from chart data and incorporating a cross-modal alignment projector, outperforming existing methods in generating high-quality chart summaries.",Vision-Language Model Summarization,
